{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset for C2B camera\n",
    "\n",
    "\n",
    "+ `exp60`\n",
    "    + 2019.06.05\n",
    "    + sensor pattern (all 0 -> all light to bucket1)\n",
    "    + 4 projector patterns consisting of 4 spatial sinusoids\n",
    "        + `Sinusoids-freq=04_bins=24_subframes=04/`\n",
    "        + 96 pattern images -> 24/frame\n",
    "    + 12 static scenes, (1000 frames/scene)\n",
    "    + 60 ms exposure / subframe\n",
    "    \n",
    "+ `7patterns`\n",
    "    + 2019.07.03\n",
    "    + sensor pattern (all 0)\n",
    "    + 7 projector pattern consisting of 4 spatial sinusoids\n",
    "        + `Sinusoids-freq=04_bins=12_subframes=07/`\n",
    "        + 84 pattern images -> 12/frame\n",
    "    + 10 static scenes, (980 frames/scene -> 140 frames to be averaged / subframe)\n",
    "    + 60 ms exposure / subframe\n",
    "    \n",
    "+ `alphabet`\n",
    "    + 2019.07.17\n",
    "    + sensor pattern (all 0)\n",
    "    + S \\in {4,5,6,7} consisting of 4 spatial sinusoids\n",
    "        + subframes numImages totalnumImages\n",
    "        + 4 24 96\n",
    "        + 5 16 80\n",
    "        + 6 16 96\n",
    "        + 7 12 84\n",
    "    + scene is snellen chart and alphabets (1000 frames / S)\n",
    "    + 60ms exposure / subframe\n",
    "\n",
    "+ `noise_wrt_sensormask`\n",
    "    + 2019.08.03\n",
    "    + 4 projector patterns consisting of 4 spatial sinusoids\n",
    "        + `Sinusoids-freq=04_bins=24_subframes=04/`\n",
    "        + 96 pattern images -> 24/frame\n",
    "    + sensor pattern\n",
    "        + `allblack` all light goes to bucket 1\n",
    "        + `bayer` sensor pattern\n",
    "    + 60 exposure / subframe\n",
    "\n",
    "+ `alphabet_const_totalexp`\n",
    "    + 2019.08.03\n",
    "    + sensor pattern (all 0)\n",
    "    + S \\in {4,5,6,7}\n",
    "        + subframes numImages totalnumImages exposure_time\n",
    "        + 4 24 96 105\n",
    "        + 5 16 80 84\n",
    "        + 6 16 96 70\n",
    "        + 7 12 84 60\n",
    "    + fixed total exposure time of 420\n",
    "        + divide by S to get exposure time for 1 subframe \n",
    "        + note acquisition time is same for different subframe\n",
    "        + a more fair experimental setup takes into account mask upload time (which is not part of subframe exposure set), this implies that the exposure time for each subframe is even smaller\n",
    "    + projector pattern \n",
    "        + optimized (parsa/wenjian's projector patterns for ZNCC decoder)\n",
    "        + sinusoids (4 spatial sinusoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "import demosaicing as dm\n",
    "import importlib; importlib.reload(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "plt.rcParams['figure.figsize'] = (20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    'organized',\n",
    "    'groundtruth'\n",
    "]\n",
    "\n",
    "# topdir = \"../data/exp60\"\n",
    "# first_pattern_indices = [0,1,2,3]\n",
    "# n_patterns = len(first_pattern_indices)\n",
    "# n_frames_total = 1000\n",
    "# n_frames_per_pattern = 250  # pick one myself\n",
    "# n_scenes = 12\n",
    "# blacklvlpath = \"../data/blacklevel_all1/blacklevel.mat\"\n",
    "\n",
    "# topdir = \"../data/7patterns\"\n",
    "# first_pattern_indices = [0,1,2,3,4,5,6]\n",
    "# n_patterns = len(first_pattern_indices)\n",
    "# n_frames_total = 980\n",
    "# n_frames_per_pattern = 140  # pick one myself\n",
    "# n_scenes = 10\n",
    "# blacklvlpath = \"../data/blacklevel_all1/blacklevel.mat\"\n",
    "\n",
    "# S = 7\n",
    "# topdir = \"../data/alphabet\"\n",
    "# n_frames_total = 1000\n",
    "# first_pattern_indices = list(range(S))\n",
    "# n_patterns = len(first_pattern_indices)\n",
    "# n_frames_per_pattern = 1000//(S*10)*10  # pick one myself\n",
    "# n_scenes = 1\n",
    "# blacklist += ['alphabet4', 'alphabet5', 'alphabet6']\n",
    "# blacklvlpath = \"../data/alphabet_blacklvl/blacklevel.mat\"\n",
    "\n",
    "\n",
    "# topdir = \"../data/noise_wrt_sensormask\"\n",
    "# first_pattern_indices = [0,1,2,3]\n",
    "# n_patterns = len(first_pattern_indices)\n",
    "# n_frames_total = 1000\n",
    "# n_frames_per_pattern = 250  # pick one myself\n",
    "# n_scenes = 2\n",
    "# blacklvlpath = \"../data/blacklevel_all1/blacklevel.mat\"\n",
    "\n",
    "\n",
    "S = 7\n",
    "topdir = \"../data/alphabet_const_totalexp\"\n",
    "n_frames_total = 1000\n",
    "first_pattern_indices = list(range(S))\n",
    "n_patterns = len(first_pattern_indices)\n",
    "n_frames_per_pattern = 1000//(S*10)*10  # pick one myself\n",
    "n_scenes = 2\n",
    "blacklist += [f'optimizedpattern_S={x}'  for x in filter(lambda x: x != S,[4,5,6,7])]\n",
    "blacklist += [f'sinusoidalpattern_S={x}' for x in filter(lambda x: x != S,[4,5,6,7])]\n",
    "blacklvlpath = \"../data/alphabet_blacklvl/blacklevel.mat\"\n",
    "\n",
    "assert(n_frames_per_pattern <= n_frames_total/n_patterns)\n",
    "imgsize = (176, 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklvl = scipy.io.loadmat(blacklvlpath);\n",
    "blacklvl = blacklvl[\"blacklvl\"]\n",
    "# applies blacklevel for bucket1\n",
    "def apply_blacklvl(im):\n",
    "    return np.maximum(im.astype(np.float64)-np.squeeze(blacklvl[0,:,:]),np.zeros(np.shape(im)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [x for x in os.listdir(topdir) if not x.startswith('.') and x not in blacklist]\n",
    "scenes = scenes[:n_scenes]\n",
    "scenes = {k: f'{os.path.join(topdir, k)}/bucket1*.png' for k in scenes}\n",
    "scenes = {k: sorted(glob.glob(v)) for k,v in scenes.items()}\n",
    "assert all([len(v) == n_frames_total for k,v in scenes.items()]), f'{[len(v) for k,v in scenes.items()]}'\n",
    "\n",
    "stacks = {k: None for k in scenes.keys()}\n",
    "for k,s in scenes.items():\n",
    "    \n",
    "    videos = np.zeros((len(s),*imgsize))\n",
    "    for i,imgpath in enumerate(s):\n",
    "        videos[i,:,:] = apply_blacklvl(cv.imread(imgpath, cv.IMREAD_GRAYSCALE))\n",
    "    \n",
    "    # since images corresponding to patterns [0,1,2,3] not in order at some point\n",
    "    #     compute distance (frobenius norm) of images, and sort the frames by increasing distance metric\n",
    "    frame_distance = np.zeros((len(first_pattern_indices),len(s)))\n",
    "    for i in range(len(first_pattern_indices)):\n",
    "        for j in range(len(s)):\n",
    "            frame_distance[i,j] = np.linalg.norm(videos[i,:,:]-videos[j,:,:,],'fro')\n",
    "\n",
    "    frame_distance = frame_distance.argsort(axis=1)\n",
    "    frame_distance = {i: frame_distance[i,:] for i in first_pattern_indices}\n",
    "    #     {pattern_id: [idx_to_closest_img, indx_to_second_closest_img, ...]}\n",
    "    \n",
    "    \n",
    "    # now stack the first several for each pattern\n",
    "    #     (4, 176, 288, n_frames_per_pattern)\n",
    "    stack = np.zeros((n_patterns,*imgsize,n_frames_per_pattern), dtype=np.uint8)\n",
    "    for pattern_id,indices_to_sorted in frame_distance.items():\n",
    "        for j,imgidx in enumerate(indices_to_sorted[:n_frames_per_pattern]):\n",
    "            stack[pattern_id,:,:,j] = videos[imgidx,:,:]\n",
    "    \n",
    "    print(f'stacking [ {n_frames_per_pattern} images / {n_patterns} patterns ] for scene={k}')\n",
    "    stack = np.mean(stack/255., axis=3)\n",
    "    stack = (stack*255).astype(np.uint8)\n",
    "    stacks[k] = stack\n",
    "    #     {k: (4, 176, 288)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_pattern_display = 4\n",
    "for scene, stack in stacks.items():\n",
    "    imgs = [stack[i,:,:] for i in range(n_pattern_display)] + \\\n",
    "            [cv.imread(scenes[scene][0], cv.IMREAD_GRAYSCALE)]\n",
    "\n",
    "    desc = [f'scene={scene} pattern={i}' for i in range(n_pattern_display)] + ['rand noisy']\n",
    "    dm.show_grayscales(imgs, desc, layouts=f'1{n_pattern_display+1}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene,stack in stacks.items():\n",
    "\n",
    "    outputdir = os.path.join(topdir,'organized')\n",
    "    if not os.path.isdir(outputdir):\n",
    "        os.makedirs(outputdir, exist_ok=True)\n",
    "    print(f'outputing {n_patterns} stacked images for ({scene}) to [{outputdir}]')\n",
    "\n",
    "    for i in range(n_patterns):\n",
    "        cv.imwrite(os.path.join(outputdir, f'{scene}_{i}.png'), stack[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv_project] *",
   "language": "python",
   "name": "conda-env-cv_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
