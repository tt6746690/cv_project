
@article{saldnerTemporalPhaseUnwrapping1997,
	title = {Temporal phase unwrapping: application to surface profiling of discontinuous objects},
	volume = {36},
	issn = {0003-6935, 1539-4522},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ao-36-13-2770},
	doi = {10.1364/AO.36.002770},
	shorttitle = {Temporal phase unwrapping},
	pages = {2770},
	number = {13},
	journaltitle = {Applied Optics},
	shortjournal = {Appl. Opt.},
	author = {Saldner, H. O. and Huntley, J. M.},
	urldate = {2019-10-14},
	date = {1997-05-01},
	langid = {english},
	keywords = {tbr},
	file = {Saldner_Huntley_1997_Temporal phase unwrapping - application to surface profiling of discontinuous objects.pdf:/Users/wpq/Dropbox (MIT)/zotero/Saldner_Huntley_1997_Temporal phase unwrapping - application to surface profiling of discontinuous objects.pdf:application/pdf}
}

@inproceedings{morenoEmbeddedPhaseShifting2015,
	title = {Embedded phase shifting: Robust phase shifting with embedded signals},
	doi = {10.1109/CVPR.2015.7298843},
	shorttitle = {Embedded phase shifting},
	abstract = {We introduce Embedded {PS}, a new robust and accurate phase shifting algorithm for 3D scanning. The method projects only high frequency sinusoidal patterns in order to reduce errors due to global illumination effects, such as subsurface scattering and interreflections. The frequency set for the projected patterns is specially designed so that our algorithm can extract a set of embedded low frequency sinusoidals with simple math. All the signals, patterns high and embedded low frequencies, are used with temporal phase unwrapping to compute absolute phase values in closed-form, without quantization or approximation via {LUT}, resulting in fast computation. The absolute phases provide correspondences from projector to camera pixels which enable to recover 3D points using optical triangulation. The algorithm estimates multiple absolute phase values per pixel which are combined to reduce measurement noise while preserving fine details. We prove that embedded periodic signals can be recovered from any periodic signal, not just sinusoidal signals, which may result in further improvements for other 3D imaging methods. Several experiments are presented showing that our algorithm produces more robust and accurate 3D scanning results than state-of-the-art methods for challenging surface materials, with an equal or smaller number of projected patterns and at lower computational cost.},
	eventtitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {2301--2309},
	booktitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Moreno, D. and Son, K. and Taubin, G.},
	date = {2015-06},
	keywords = {tbr},
	file = {Moreno et al_2015_Embedded phase shifting - Robust phase shifting with embedded signals.pdf:/Users/wpq/Dropbox (MIT)/zotero/Moreno et al_2015_Embedded phase shifting - Robust phase shifting with embedded signals.pdf:application/pdf}
}

@article{gengStructuredlight3DSurface2011,
	title = {Structured-light 3D surface imaging: a tutorial},
	volume = {3},
	rights = {\&\#169; 2011 {OSA}},
	issn = {1943-8206},
	url = {https://www.osapublishing.org/aop/abstract.cfm?uri=aop-3-2-128},
	doi = {10.1364/AOP.3.000128},
	shorttitle = {Structured-light 3D surface imaging},
	abstract = {We provide a review of recent advances in 3D surface imaging technologies. We focus particularly on noncontact 3D surface measurement techniques based on structured illumination. The high-speed and high-resolution pattern projection capability offered by the digital light projection technology, together with the recent advances in imaging sensor technologies, may enable new generation systems for 3D surface measurement applications that will provide much better functionality and performance than existing ones in terms of speed, accuracy, resolution, modularization, and ease of use. Performance indexes of 3D imaging system are discussed, and various 3D surface imaging schemes are categorized, illustrated, and compared. Calibration techniques are also discussed, since they play critical roles in achieving the required precision. Numerous applications of 3D surface imaging technologies are discussed with several examples.},
	pages = {128--160},
	number = {2},
	journaltitle = {Advances in Optics and Photonics},
	shortjournal = {Adv. Opt. Photon., {AOP}},
	author = {Geng, Jason},
	urldate = {2019-10-13},
	date = {2011-06-30},
	keywords = {tbr},
	file = {Geng_2011_Structured-light 3D surface imaging - a tutorial.pdf:/Users/wpq/Dropbox (MIT)/zotero/Geng_2011_Structured-light 3D surface imaging - a tutorial.pdf:application/pdf}
}

@inproceedings{guptaGeometricPerspectiveStructured2018,
	title = {A Geometric Perspective on Structured Light Coding},
	url = {http://openaccess.thecvf.com/content_ECCV_2018/html/Mohit_Gupta_A_Geometric_Perspective_ECCV_2018_paper.html},
	eventtitle = {Proceedings of the European Conference on Computer Vision ({ECCV})},
	pages = {87--102},
	author = {Gupta, Mohit and Nakhate, Nikhil},
	urldate = {2019-11-26},
	date = {2018},
	keywords = {read},
	file = {Gupta_Nakhate_2018_A Geometric Perspective on Structured Light Coding.pdf:/Users/wpq/Dropbox (MIT)/zotero/Gupta_Nakhate_2018_A Geometric Perspective on Structured Light Coding.pdf:application/pdf}
}

@inproceedings{mirdehghanOptimalStructuredLight2018,
	title = {Optimal Structured Light a la Carte},
	doi = {10.1109/CVPR.2018.00654},
	abstract = {We consider the problem of automatically generating sequences of structured-light patterns for active stereo triangulation of a static scene. Unlike existing approaches that use predetermined patterns and reconstruction algorithms tied to them, we generate patterns on the fly in response to generic specifications: number of patterns, projector-camera arrangement, workspace constraints, spatial frequency content, etc. Our pattern sequences are specifically optimized to minimize the expected rate of correspondence errors under those specifications for an unknown scene, and are coupled to a sequence-independent algorithm for perpixel disparity estimation. To achieve this, we derive an objective function that is easy to optimize and follows from first principles within a maximum-likelihood framework. By minimizing it, we demonstrate automatic discovery of pattern sequences, in under three minutes on a laptop, that can outperform state-of-the-art triangulation techniques.},
	eventtitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {6248--6257},
	booktitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	author = {Mirdehghan, P. and Chen, W. and Kutulakos, K. N.},
	date = {2018-06},
	keywords = {read},
	file = {Mirdehghan et al_2018_Optimal Structured Light a la Carte.pdf:/Users/wpq/Dropbox (MIT)/zotero/Mirdehghan et al_2018_Optimal Structured Light a la Carte.pdf:application/pdf}
}

@inproceedings{guptaMicroPhaseShifting2012,
	location = {Providence, {RI}},
	title = {Micro Phase Shifting},
	isbn = {978-1-4673-1228-8 978-1-4673-1226-4 978-1-4673-1227-1},
	url = {http://ieeexplore.ieee.org/document/6247753/},
	doi = {10.1109/CVPR.2012.6247753},
	abstract = {We consider the problem of shape recovery for real world scenes, where a variety of global illumination (interreﬂections, subsurface scattering, etc.) and illumination defocus eﬀects are present. These eﬀects introduce systematic and often signiﬁcant errors in the recovered shape. We introduce a structured light technique called Micro Phase Shifting, which overcomes these problems. The key idea is to project sinusoidal patterns with frequencies limited to a narrow, highfrequency band. These patterns produce a set of images over which global illumination and defocus eﬀects remain constant for each point in the scene. This enables high quality reconstructions of scenes which have traditionally been considered hard, using only a small number of images. We also derive theoretical lower bounds on the number of input images needed for phase shifting and show that Micro {PS} achieves the bound.},
	eventtitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {813--820},
	booktitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition},
	publisher = {{IEEE}},
	author = {Gupta, M. and Nayar, S. K.},
	urldate = {2019-07-19},
	date = {2012-06},
	langid = {english},
	keywords = {read},
	file = {Gupta_Nayar_2012_Micro Phase Shifting.pdf:/Users/wpq/Dropbox (MIT)/zotero/Gupta_Nayar_2012_Micro Phase Shifting.pdf:application/pdf}
}

@article{salviPatternCodificationStrategies2004,
	title = {Pattern codification strategies in structured light systems},
	volume = {37},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320303003303},
	doi = {10.1016/j.patcog.2003.10.002},
	series = {Agent Based Computer Vision},
	abstract = {Coded structured light is considered one of the most reliable techniques for recovering the surface of objects. This technique is based on projecting a light pattern and viewing the illuminated scene from one or more points of view. Since the pattern is coded, correspondences between image points and points of the projected pattern can be easily found. The decoded points can be triangulated and 3D information is obtained. We present an overview of the existing techniques, as well as a new and definitive classification of patterns for structured light sensors. We have implemented a set of representative techniques in this field and present some comparative results. The advantages and constraints of the different patterns are also discussed.},
	pages = {827--849},
	number = {4},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Salvi, Joaquim and Pagès, Jordi and Batlle, Joan},
	urldate = {2019-07-19},
	date = {2004-04-01},
	keywords = {3D measuring devices, Active stereo, Coded patterns, Computer vision, Structured light, read},
	file = {Salvi et al_2004_Pattern codification strategies in structured light systems.pdf:/Users/wpq/Dropbox (MIT)/zotero/Salvi et al_2004_Pattern codification strategies in structured light systems.pdf:application/pdf}
}

@inproceedings{hornOptimalStructuredLight1997,
	title = {Toward optimal structured light patterns},
	doi = {10.1109/IM.1997.603845},
	abstract = {A methodology for the optimal design of projection patterns for stereometric structured light systems is presented. The similarity as well as the difference between the design of projection patterns and the design of optimal signals for digital communication are discussed. The design of K projection patterns for a structured light system with L distinct planes of light is shown to be equivalent to the placement of L points in a K dimensional space subject to certain constraints. optimal design in the {MSE} sense is defined, but shown to lead to an intractable multi-parameter global optimization problem. Intuitively appealing suboptimal solutions derived from the family of K dimensional space-filling Hilbert curves are obtained. Preliminary experimental results are presented.},
	eventtitle = {Proceedings. International Conference on Recent Advances in 3-D Digital Imaging and Modeling (Cat. No.97TB100134)},
	pages = {28--35},
	booktitle = {Proceedings. International Conference on Recent Advances in 3-D Digital Imaging and Modeling (Cat. No.97TB100134)},
	author = {Horn, E. and Kiryati, N.},
	date = {1997-05},
	note = {{ISSN}: null},
	keywords = {read},
	file = {Horn_Kiryati_1997_Toward optimal structured light patterns.pdf:/Users/wpq/Dropbox (MIT)/zotero/Horn_Kiryati_1997_Toward optimal structured light patterns.pdf:application/pdf}
}

@article{posdamerSurfaceMeasurementSpaceencoded1982,
	title = {Surface measurement by space-encoded projected beam systems},
	volume = {18},
	issn = {0146664X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0146664X8290096X},
	doi = {10.1016/0146-664X(82)90096-X},
	pages = {1--17},
	number = {1},
	journaltitle = {Computer Graphics and Image Processing},
	shortjournal = {Computer Graphics and Image Processing},
	author = {Posdamer, J.L and Altschuler, M.D},
	urldate = {2020-02-08},
	date = {1982-01},
	langid = {english},
	keywords = {tbr},
	file = {Posdamer_Altschuler_1982_Surface measurement by space-encoded projected beam systems.pdf:/Users/wpq/Dropbox (MIT)/zotero/Posdamer_Altschuler_1982_Surface measurement by space-encoded projected beam systems.pdf:application/pdf}
}

@article{gushovAutomaticProcessingFringe1991,
	title = {Automatic processing of fringe patterns in integer interferometers},
	volume = {14},
	issn = {01438166},
	url = {https://linkinghub.elsevier.com/retrieve/pii/014381669190055X},
	doi = {10.1016/0143-8166(91)90055-X},
	pages = {311--324},
	number = {4},
	journaltitle = {Optics and Lasers in Engineering},
	shortjournal = {Optics and Lasers in Engineering},
	author = {Gushov, V.I. and Solodkin, Yu.N.},
	urldate = {2020-02-09},
	date = {1991},
	langid = {english},
	keywords = {tbr},
	file = {Gushov_Solodkin_1991_Automatic processing of fringe patterns in integer interferometers.pdf:/Users/wpq/Dropbox (MIT)/zotero/Gushov_Solodkin_1991_Automatic processing of fringe patterns in integer interferometers.pdf:application/pdf}
}

@online{satoThreedimensionalSurfaceMeasurement1985,
	title = {Three-dimensional surface measurement by space encoding range imaging},
	url = {/paper/Three-dimensional-surface-measurement-by-space-Sato-Inokuchi/73d9b92a313cfd2c97d4ebe8ab84d67a828c8e2a},
	abstract = {Semantic Scholar extracted view of \&quot;Three-dimensional surface measurement by space encoding range imaging\&quot; by K. Sato et al.},
	author = {Sato, K. and Inokuchi, Seiji},
	urldate = {2020-05-24},
	date = {1985},
	langid = {english},
	note = {Library Catalog: www.semanticscholar.org},
	keywords = {tbr}
}

@article{salviStateArtStructured2010,
	title = {A state of the art in structured light patterns for surface profilometry},
	volume = {43},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S003132031000124X},
	doi = {10.1016/j.patcog.2010.03.004},
	abstract = {Shape reconstruction using coded structured light is considered one of the most reliable techniques to recover object surfaces. Having a calibrated projector–camera pair, a light pattern is projected onto the scene and imaged by the camera. Correspondences between projected and recovered patterns are found and used to extract 3D surface information. This paper presents an up-to-date review and a new classification of the existing techniques. Some of these techniques have been implemented and compared, obtaining both qualitative and quantitative results. The advantages and drawbacks of the different patterns and their potentials are discussed.},
	pages = {2666--2680},
	number = {8},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Salvi, Joaquim and Fernandez, Sergio and Pribanic, Tomislav and Llado, Xavier},
	urldate = {2020-05-24},
	date = {2010-08-01},
	langid = {english},
	keywords = {tbr},
	file = {Salvi et al_2010_A state of the art in structured light patterns for surface profilometry.pdf:/Users/wpq/Dropbox (MIT)/zotero/Salvi et al_2010_A state of the art in structured light patterns for surface profilometry.pdf:application/pdf}
}

@article{pribanicEfficientMultiplePhase2010,
	title = {Efficient multiple phase shift patterns for dense 3D acquisition in structured light scanning},
	volume = {28},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885610000107},
	doi = {10.1016/j.imavis.2010.01.003},
	abstract = {Although phase shifts ({PS}) are frequently used to acquire colored surfaces of static objects, especially when acquisition time is not critical, the periodic nature of relative (wrapped) {PS} maps makes it necessary to deal with the issue of phase unwrapping. Consequently, multiple phase shifts ({MPS}) have been widely used as an alternative, but this usually involves a large number of different {PS} maps to unwrap an absolute (unique) phase. In this paper we propose a new {MPS} method to unwrap a phase and accurately perform the dense 3D acquisition of neutral and colored objects using only two {PS} maps. Accuracy is reported including a quantitative and qualitative evaluation of the results.},
	pages = {1255--1266},
	number = {8},
	journaltitle = {Image and Vision Computing},
	shortjournal = {Image and Vision Computing},
	author = {Pribanić, Tomislav and Mrvoš, Saša and Salvi, Joaquim},
	urldate = {2020-05-26},
	date = {2010-08-01},
	langid = {english},
	keywords = {tbr},
	file = {Pribanic et al_2010_Efficient multiple phase shift patterns for dense 3D acquisition in structured light scanning.pdf:/Users/wpq/Dropbox (MIT)/zotero/Pribanic et al_2010_Efficient multiple phase shift patterns for dense 3D acquisition in structured light scanning.pdf:application/pdf}
}

@article{gushovAutomaticProcessingFringe1991a,
	title = {Automatic processing of fringe patterns in integer interferometers},
	volume = {14},
	issn = {0143-8166},
	url = {http://www.sciencedirect.com/science/article/pii/014381669190055X},
	doi = {10.1016/0143-8166(91)90055-X},
	abstract = {The purpose of this paper is to describe a new method for determination of the total phase difference of light waves without interference fringe counting. One can build up an interferometer for measurement of displacements in which the displacements are determined only by the final values of intensity regardless of the velocity and any prior displacements that caused the present one. The same thing holds true for vibration, relief parameters and other values to be measured. Such an interferometer is devisable thanks to two underlying ideas: first, the application of controllable phase shift, and secondly, the use of properties of integer divisability.},
	pages = {311--324},
	number = {4},
	journaltitle = {Optics and Lasers in Engineering},
	shortjournal = {Optics and Lasers in Engineering},
	author = {Gushov, V. I. and Solodkin, Yu. N.},
	urldate = {2020-05-26},
	date = {1991-01-01},
	langid = {english},
	keywords = {read},
	file = {Gushov_Solodkin_1991_Automatic processing of fringe patterns in integer interferometers.pdf:/Users/wpq/Dropbox (MIT)/zotero/Gushov_Solodkin_1991_Automatic processing of fringe patterns in integer interferometers2.pdf:application/pdf}
}

@online{Tt6746690CvProject,
	title = {tt6746690/cv\_project},
	url = {https://github.com/tt6746690/cv_project},
	abstract = {Contribute to tt6746690/cv\_project development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2020-06-03},
	langid = {english},
	note = {Library Catalog: github.com}
}

@inproceedings{rosmanInformationDrivenAdaptiveStructuredLight2016,
	title = {Information-Driven Adaptive Structured-Light Scanners},
	doi = {10.1109/CVPR.2016.101},
	abstract = {Sensor planning and active sensing, long studied in robotics, adapt sensor parameters to maximize a utility function while constraining resource expenditures. Here we consider information gain as the utility function. While these concepts are often used to reason about 3D sensors, these are usually treated as a predefined, black-box, component. In this paper we show how the same principles can be used as part of the 3D sensor. We describe the relevant generative model for structured-light 3D scanning and show how adaptive pattern selection can maximize information gain in an open-loop-feedback manner. We then demonstrate how different choices of relevant variable sets (corresponding to the subproblems of locatization and mapping) lead to different criteria for pattern selection and can be computed in an online fashion. We show results for both subproblems with several pattern dictionary choices and demonstrate their usefulness for pose estimation and depth acquisition.},
	eventtitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {874--883},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Rosman, Guy and Rus, Daniela and Fisher, John W.},
	date = {2016-06},
	note = {{ISSN}: 1063-6919},
	keywords = {tbr},
	file = {Rosman et al_2016_Information-Driven Adaptive Structured-Light Scanners.pdf:/Users/wpq/Dropbox (MIT)/zotero/Rosman et al_2016_Information-Driven Adaptive Structured-Light Scanners.pdf:application/pdf}
}

@inproceedings{rosmanSparseModelingShape2012,
	title = {Sparse Modeling of Shape from Structured Light},
	doi = {10.1109/3DIMPVT.2012.20},
	abstract = {Structured light depth reconstruction is among the most commonly used methods for 3D data acquisition. Yet, in most structured light methods, modeling of the acquired scene is crude, and is executed separately from the decoding phase. Here, we bridge this gap by viewing the reconstruction process via a probabilistic model combining illumination and shape. Specifically, an alternating minimization algorithm for structured light reconstruction is presented, incorporating a sparsity-based prior for the local surface model. Integrating this 3D surface prior into a probabilistic view of the reconstruction phase results in a robust estimation of the scene depth. We formulate and minimize reconstruction error and demonstrate performance of the algorithm on data from a structured light scanner. The results demonstrate the robustness of our algorithm to scanning artifacts under low {SNR} conditions and object motion.},
	eventtitle = {Visualization Transmission 2012 Second International Conference on 3D Imaging, Modeling, Processing},
	pages = {456--463},
	booktitle = {Visualization Transmission 2012 Second International Conference on 3D Imaging, Modeling, Processing},
	author = {Rosman, Guy and Dubrovina, Anastasia and Kimmel, Ron},
	date = {2012-10},
	note = {{ISSN}: 1550-6185},
	keywords = {good, read},
	file = {Rosman et al_2012_Sparse Modeling of Shape from Structured Light.pdf:/Users/wpq/Dropbox (MIT)/zotero/Rosman et al_2012_Sparse Modeling of Shape from Structured Light.pdf:application/pdf}
}

@inproceedings{barronShapeAlbedoIllumination2012,
	title = {Shape, albedo, and illumination from a single image of an unknown object},
	doi = {10.1109/CVPR.2012.6247693},
	abstract = {We address the problem of recovering shape, albedo, and illumination from a single grayscale image of an object, using shading as our primary cue. Because this problem is fundamentally underconstrained, we construct statistical models of albedo and shape, and define an optimization problem that searches for the most likely explanation of a single image. We present two priors on albedo which encourage local smoothness and global sparsity, and three priors on shape which encourage flatness, outward-facing orientation at the occluding contour, and local smoothness. We present an optimization technique for using these priors to recover shape, albedo, and a spherical harmonic model of illumination. Our model, which we call {SAIFS} (shape, albedo, and illumination from shading) produces reasonable results on arbitrary grayscale images taken in the real world, and outperforms all previous grayscale “intrinsic image” - style algorithms on the {MIT} Intrinsic Images dataset.},
	eventtitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {334--341},
	booktitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition},
	author = {Barron, Jonathan T. and Malik, Jitendra},
	date = {2012-06},
	note = {{ISSN}: 1063-6919},
	keywords = {tbr},
	file = {Barron_Malik_2012_Shape, albedo, and illumination from a single image of an unknown object.pdf:/Users/wpq/Dropbox (MIT)/zotero/Barron_Malik_2012_Shape, albedo, and illumination from a single image of an unknown object.pdf:application/pdf}
}

@inproceedings{schoberDynamicTimeofFlight2017,
	title = {Dynamic Time-of-Flight},
	doi = {10.1109/CVPR.2017.26},
	abstract = {Time-of-flight ({TOF}) depth cameras provide robust depth inference at low power requirements in a wide variety of consumer and industrial applications. These cameras reconstruct a single depth frame from a given set of infrared ({IR}) frames captured over a very short exposure period. Operating in this mode the camera essentially forgets all information previously captured - and performs depth inference from scratch for every frame. We challenge this practice and propose using previously captured information when inferring depth. An inherent problem we have to address is camera motion over this longer period of collecting observations. We derive a probabilistic framework combining a simple but robust model of camera and object motion, together with an observation model. This combination allows us to integrate information over multiple frames while remaining robust to rapid changes. Operating the camera in this manner has implications in terms of both computational efficiency and how information should be captured. We address these two issues and demonstrate a realtime {TOF} system with robust temporal integration that improves depth accuracy over strong baseline methods including adaptive spatio-temporal filters.},
	eventtitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {170--179},
	booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Schober, Michael and Adam, Amit and Yair, Omer and Mazor, Shai and Nowozin, Sebastian},
	date = {2017-07},
	note = {{ISSN}: 1063-6919},
	keywords = {tbr},
	file = {Schober et al_2017_Dynamic Time-of-Flight.pdf:/Users/wpq/Dropbox (MIT)/zotero/Schober et al_2017_Dynamic Time-of-Flight.pdf:application/pdf}
}

@article{adamBayesianTimeofFlightRealtime2015,
	title = {Bayesian Time-of-Flight for Realtime Shape, Illumination and Albedo},
	url = {http://arxiv.org/abs/1507.06173},
	abstract = {We propose a computational model for shape, illumination and albedo inference in a pulsed time-of-flight ({TOF}) camera. In contrast to {TOF} cameras based on phase modulation, our camera enables general exposure profiles. This results in added flexibility and requires novel computational approaches. To address this challenge we propose a generative probabilistic model that accurately relates latent imaging conditions to observed camera responses. While principled, realtime inference in the model turns out to be infeasible, and we propose to employ efficient non-parametric regression trees to approximate the model outputs. As a result we are able to provide, for each pixel, at video frame rate, estimates and uncertainty for depth, effective albedo, and ambient light intensity. These results we present are state-of-the-art in depth imaging. The flexibility of our approach allows us to easily enrich our generative model. We demonstrate that by extending the original single-path model to a two-path model, capable of describing some multipath effects. The new model is seamlessly integrated in the system at no additional computational cost. Our work also addresses the important question of optimal exposure design in pulsed {TOF} systems. Finally, for benchmark purposes and to obtain realistic empirical priors of multipath and insights into this phenomena, we propose a physically accurate simulation of multipath phenomena.},
	journaltitle = {{arXiv}:1507.06173 [cs]},
	author = {Adam, Amit and Dann, Christoph and Yair, Omer and Mazor, Shai and Nowozin, Sebastian},
	urldate = {2020-06-10},
	date = {2015-07-22},
	eprinttype = {arxiv},
	eprint = {1507.06173},
	keywords = {tbr},
	file = {Adam et al_2015_Bayesian Time-of-Flight for Realtime Shape, Illumination and Albedo.pdf:/Users/wpq/Dropbox (MIT)/zotero/Adam et al_2015_Bayesian Time-of-Flight for Realtime Shape, Illumination and Albedo.pdf:application/pdf}
}