
@inproceedings{changOneNetworkSolve2017,
  address = {{Venice}},
  title = {One {{Network}} to {{Solve Them All}} \textemdash{} {{Solving Linear Inverse Problems Using Deep Projection Models}}},
  isbn = {978-1-5386-1032-9},
  abstract = {While deep learning methods have achieved state-of-theart performance in many challenging inverse problems like image inpainting and super-resolution, they invariably involve problem-specific training of the networks. Under this approach, each inverse problem requires its own dedicated network. In scenarios where we need to solve a wide variety of problems, e.g., on a mobile camera, it is inefficient and expensive to use these problem-specific networks. On the other hand, traditional methods using analytic signal priors can be used to solve any linear inverse problem; this often comes with a performance that is worse than learning-based methods. In this work, we provide a middle ground between the two kinds of methods \textemdash{} we propose a general framework to train a single deep neural network that solves arbitrary linear inverse problems. We achieve this by training a network that acts as a quasi-projection operator for the set of natural images and show that any linear inverse problem involving natural images can be solved using iterative methods. We empirically show that the proposed framework demonstrates superior performance over traditional methods using wavelet sparsity prior while achieving performance comparable to specially-trained networks on tasks including compressive sensing and pixel-wise inpainting.},
  language = {en},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  publisher = {{IEEE}},
  doi = {10.1109/ICCV.2017.627},
  author = {Chang, J. H. Rick and Li, Chun-Liang and Poczos, Barnabas and Kumar, B. V. K. Vijaya and Sankaranarayanan, Aswin C.},
  month = oct,
  year = {2017},
  pages = {5889-5898},
  file = {/Users/markwang/drive/zotero/Chang et al_2017_One Network to Solve Them All — Solving Linear Inverse Problems Using Deep Projection Models.pdf}
}

@incollection{weiCodedTwoBucketCameras2018,
  address = {{Cham}},
  title = {Coded {{Two}}-{{Bucket Cameras}} for {{Computer Vision}}},
  volume = {11207},
  isbn = {978-3-030-01218-2 978-3-030-01219-9},
  abstract = {We introduce coded two-bucket (C2B) imaging, a new operating principle for computational sensors with applications in active 3D shape estimation and coded-exposure imaging. A C2B sensor modulates the light arriving at each pixel by controlling which of the pixel's two ``buckets'' should integrate it. C2B sensors output two images per video frame\textemdash{}one per bucket\textemdash{}and allow rapid, fully-programmable, per-pixel control of the active bucket. Using these properties as a starting point, we (1) develop an image formation model for these sensors, (2) couple them with programmable light sources to acquire illumination mosaics, i.e., images of a scene under many different illumination conditions whose pixels have been multiplexed and acquired in one shot, and (3) show how to process illumination mosaics to acquire live disparity or normal maps of dynamic scenes at the sensor's native resolution. We present the first experimental demonstration of these capabilities, using a fully-functional C2B camera prototype. Key to this unique prototype is a novel programmable CMOS sensor that we designed from the ground up, fabricated and turned into a working system.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  publisher = {{Springer International Publishing}},
  author = {Wei, Mian and Sarhangnejad, Navid and Xia, Zhengfan and Gusev, Nikita and Katic, Nikola and Genov, Roman and Kutulakos, Kiriakos N.},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  keywords = {c2b,mian},
  pages = {55-73},
  file = {/Users/markwang/drive/zotero/Wei et al_2018_Coded Two-Bucket Cameras for Computer Vision.pdf},
  doi = {10.1007/978-3-030-01219-9_4}
}

@incollection{dempeOptimalityConditionsSimple1970,
  title = {Optimality {{Conditions}} for a {{Simple Convex Bilevel Programming Problem}}},
  volume = {47},
  abstract = {The problem to find a best solution within the set of optimal solutions of a convex optimization problem is modeled as a bilevel
programming problem. It is shown that regularity conditions like Slater's constraint qualification are never satisfied for
this problem. If the lower-level problem is replaced with its (necessary and sufficient) optimality conditions, it is possible
to derive a necessary optimality condition for the resulting problem. An example is used to show that this condition in not
sufficient even if the initial problem is a convex one. If the lower-level problem is replaced using its optimal value, it
is possible to obtain an optimality condition that is both necessary and sufficient in the convex case.},
  booktitle = {Variational {{Analysis}} and {{Generalized Differentiation}} in {{Optimization}} and {{Control}}},
  author = {Dempe, S and Dinh, N and Dutta, Joydeep},
  month = jan,
  year = {1970},
  keywords = {bilevel},
  pages = {149-161},
  file = {/Users/markwang/drive/zotero/Dempe et al_1970_Optimality Conditions for a Simple Convex Bilevel Programming Problem.pdf},
  doi = {10.1007/978-1-4419-0437-9_7}
}

@incollection{dempeOptimalityConditionsBilevel2006,
  address = {{Boston, MA}},
  series = {Springer {{Optimization}} and {{Its Applications}}},
  title = {Optimality Conditions for Bilevel Programming Problems},
  isbn = {978-0-387-34221-4},
  abstract = {SummaryFocus in the paper is on optimality conditions for bilevel programming problems. We start with a general condition using tangent cones of the feasible set of the bilevel programming problem to derive such conditions for the optimistic bilevel problem. More precise conditions are obtained if the tangent cone possesses an explicit description as it is possible in the case of linear lower level problems. If the optimal solution of the lower level problem is a PC 1-function, sufficient conditions for a global optimal solution of the optimistic bilevel problem can be formulated. In the second part of the paper relations of the bilevel programming problem to set-valued optimization problems and to mathematical programs with equilibrium constraints are given which can also be used to formulate optimality conditions for the original problem. Finally, a variational inequality approach is described which works well when the involved functions are monotone. It consists in a variational re-formulation of the optimality conditions and looking for a solution of the thus obtained variational inequality among the points satisfying the initial constraints. A penalty function technique is applied to get a sequence of approximate solutions converging to a solution of the original problem with monotone operators.},
  language = {en},
  booktitle = {Optimization with {{Multivalued Mappings}}: {{Theory}}, {{Applications}}, and {{Algorithms}}},
  publisher = {{Springer US}},
  author = {Dempe, Stephan and Kalashnikov, Vyatcheslav V. and Kalashnykova, Nataliya},
  editor = {Dempe, Stephan and Kalashnikov, Vyacheslav},
  year = {2006},
  keywords = {Bilevel Programming,Mathematical Programs with Equilibrium Constraints,Necessary and Sufficient Optimality Conditions,Penalty Function Techniques,Set-valued Optimization,Variational Inequality,bilevel},
  pages = {3-28},
  file = {/Users/markwang/drive/zotero/Dempe et al_2006_Optimality conditions for bilevel programming problems.pdf},
  doi = {10.1007/0-387-34221-4_1}
}

@article{boydDistributedOptimizationStatistical2011,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  volume = {3},
  issn = {1935-8237},
  abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas\textendash{}Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for {$\mathscr{l}$}1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.},
  number = {1},
  journal = {Found. Trends Mach. Learn.},
  doi = {10.1561/2200000016},
  author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  month = jan,
  year = {2011},
  keywords = {admm,boyd},
  pages = {1--122},
  file = {/Users/markwang/drive/zotero/Boyd et al_2011_Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf}
}

@unpublished{chambolleFirstorderPrimaldualAlgorithm2010,
  title = {A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging},
  abstract = {We study a first-order primal-dual algorithm for convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions, which is optimal for the complete class of non-smooth problems we are considering in this paper. We further show accelerations of the proposed algorithm to yield optimal rates on easier problems. In particular we show that we can achieve O(1/N{$^2$}) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O(1/e\^N) on problems where both are uniformly convex. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and image segmentation.},
  author = {Chambolle, Antonin and Pock, Thomas},
  month = jun,
  year = {2010},
  keywords = {Convex optimization,Dual approaches,Image reconstruction,Inverse problems,Total variation,primal-dual},
  file = {/Users/markwang/drive/zotero/Chambolle_Pock_2010_A first-order primal-dual algorithm for convex problems with applications to imaging.pdf}
}

@article{parikhProximalAlgorithms2014,
  title = {Proximal {{Algorithms}}},
  volume = {1},
  issn = {2167-3888},
  abstract = {This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton's method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
  number = {3},
  journal = {Found. Trends Optim.},
  doi = {10.1561/2400000003},
  author = {Parikh, Neal and Boyd, Stephen},
  month = jan,
  year = {2014},
  keywords = {proximal},
  pages = {127--239}
}

@article{wangBregmanAlternatingDirection2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1306.3203},
  primaryClass = {cs, math, stat},
  title = {Bregman {{Alternating Direction Method}} of {{Multipliers}}},
  abstract = {The mirror descent algorithm (MDA) generalizes gradient descent by using a Bregman divergence to replace squared Euclidean distance. In this paper, we similarly generalize the alternating direction method of multipliers (ADMM) to Bregman ADMM (BADMM), which allows the choice of different Bregman divergences to exploit the structure of problems. BADMM provides a unified framework for ADMM and its variants, including generalized ADMM, inexact ADMM and Bethe ADMM. We establish the global convergence and the \$O(1/T)\$ iteration complexity for BADMM. In some cases, BADMM can be faster than ADMM by a factor of \$O(n/\textbackslash{}log(n))\$. In solving the linear program of mass transportation problem, BADMM leads to massive parallelism and can easily run on GPU. BADMM is several times faster than highly optimized commercial software Gurobi.},
  journal = {arXiv:1306.3203 [cs, math, stat]},
  author = {Wang, Huahua and Banerjee, Arindam},
  month = jun,
  year = {2013},
  keywords = {admm,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning,bregman},
  file = {/Users/markwang/drive/zotero/Wang_Banerjee_2013_Bregman Alternating Direction Method of Multipliers.pdf;/Users/markwang/Zotero/storage/JXSW5WK5/1306.html}
}

@article{goldsteinFastAlternatingDirection2014,
  title = {Fast {{Alternating Direction Optimization Methods}}},
  volume = {7},
  abstract = {Alternating direction methods are a common tool for general mathematical programming and optimization. These methods have become particularly important in the field of variational image processing, which frequently requires the minimization of nondifferentiable objectives. This paper considers accelerated (i.e., fast) variants of two common alternating direction methods: the alternating direction method of multipliers (ADMM) and the alternating minimization algorithm (AMA). The proposed acceleration is of the form first proposed by Nesterov for gradient descent methods. In the case that the objective function is strongly convex, global convergence bounds are provided for both classical and accelerated variants of the methods. Numerical examples are presented to demonstrate the superior performance of the fast methods for a wide variety of problems.},
  number = {3},
  journal = {SIAM Journal on Imaging Sciences},
  doi = {10.1137/120896219},
  author = {Goldstein, T. and O'Donoghue, B. and Setzer, S. and Baraniuk, R.},
  month = jan,
  year = {2014},
  keywords = {admm},
  pages = {1588-1623},
  file = {/Users/markwang/drive/zotero/Goldstein et al_2014_Fast Alternating Direction Optimization Methods.pdf;/Users/markwang/Zotero/storage/TRJ7VBDT/120896219.html}
}

@article{gouldDifferentiatingParameterizedArgmin2019,
  title = {On {{Differentiating Parameterized Argmin}} and {{Argmax Problems}} with {{Application}} to {{Bi}}-Level {{Optimization}}},
  abstract = {Some recent works in machine learning and computer vision involve the solution of a bilevel optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems, including gradient descent, which is popular with current end-to-end learning approaches. In this technical report we collect some results on differentiating argmin and argmax optimization problems with and without constraints and provide some insightful motivating examples.},
  language = {en},
  author = {Gould, Stephen and Fernando, Basura and Cherian, Anoop and Anderson, Peter and Cruz, Rodrigo Santa and Guo, Edison},
  year = {2019},
  keywords = {bilevel},
  pages = {16},
  file = {/Users/markwang/drive/zotero/Gould et al_2019_On Diﬀerentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization.pdf}
}

@incollection{wangProximalDeepStructured2016,
  title = {Proximal {{Deep Structured Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  author = {Wang, Shenlong and Fidler, Sanja and Urtasun, Raquel},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  keywords = {proximal,deep},
  pages = {865--873},
  file = {/Users/markwang/drive/zotero/Wang et al_2016_Proximal Deep Structured Models.pdf;/Users/markwang/Zotero/storage/9YBZYXPZ/6074-proximal-deep-structured-models.html}
}

@article{sinhaReviewBilevelOptimization2018,
  title = {A {{Review}} on {{Bilevel Optimization}}: {{From Classical}} to {{Evolutionary Approaches}} and {{Applications}}},
  volume = {22},
  issn = {1089-778X},
  shorttitle = {A {{Review}} on {{Bilevel Optimization}}},
  abstract = {Bilevel optimization is defined as a mathematical program, where an optimization problem contains another optimization problem as a constraint. These problems have received significant attention from the mathematical programming community. Only limited work exists on bilevel problems using evolutionary computation techniques; however, recently there has been an increasing interest due to the proliferation of practical applications and the potential of evolutionary algorithms in tackling these problems. This paper provides a comprehensive review on bilevel optimization from the basic principles to solution strategies; both classical and evolutionary. A number of potential application problems are also discussed. To offer the readers insights on the prominent developments in the field of bilevel optimization, we have performed an automated text-analysis of an extended list of papers published on bilevel optimization to date. This paper should motivate evolutionary computation researchers to pay more attention to this practical yet challenging area.},
  number = {2},
  journal = {IEEE Transactions on Evolutionary Computation},
  doi = {10.1109/TEVC.2017.2712906},
  author = {Sinha, A. and Malo, P. and Deb, K.},
  month = apr,
  year = {2018},
  keywords = {bilevel,bilevel optimization,Bilevel optimization,bilevel problems,Decision making,evolutionary algorithms,evolutionary computation,Evolutionary computation,evolutionary computation techniques,Fertilizers,Linear programming,mathematical programming,Mathematical programming,mathematical programming community,optimization problem,potential application problems,Programming,Stackelberg games,text analysis},
  pages = {276-295},
  file = {/Users/markwang/drive/zotero/Sinha et al_2018_A Review on Bilevel Optimization - From Classical to Evolutionary Approaches and Applications.pdf;/Users/markwang/Zotero/storage/RDV9J8IJ/7942105.html}
}

@article{antonelloProximalGradientAlgorithms2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.01621},
  primaryClass = {eess, math},
  title = {Proximal {{Gradient Algorithms}}: {{Applications}} in {{Signal Processing}}},
  shorttitle = {Proximal {{Gradient Algorithms}}},
  abstract = {Advances in numerical optimization have supported breakthroughs in several areas of signal processing. This paper focuses on the recent enhanced variants of the proximal gradient numerical optimization algorithm, which combine quasi-Newton methods with forward-adjoint oracles to tackle large-scale problems and reduce the computational burden of many applications. These proximal gradient algorithms are here described in an easy-to-understand way, illustrating how they are able to address a wide variety of problems arising in signal processing. A new high-level modeling language is presented which is used to demonstrate the versatility of the presented algorithms in a series of signal processing application examples such as sparse deconvolution, total variation denoising, audio de-clipping and others.},
  journal = {arXiv:1803.01621 [eess, math]},
  author = {Antonello, Niccol{\`o} and Stella, Lorenzo and Patrinos, Panagiotis and {van Waterschoot}, Toon},
  month = mar,
  year = {2018},
  keywords = {proximal,Mathematics - Optimization and Control,D.2,Electrical Engineering and Systems Science - Signal Processing,G.1.6,I.2,signalprocessing},
  file = {/Users/markwang/drive/zotero/Antonello et al_2018_Proximal Gradient Algorithms - Applications in Signal Processing.pdf;/Users/markwang/Zotero/storage/XN8JQBL2/1803.html}
}

@article{dempeSolutionBilevelOptimization2019,
  title = {Solution of Bilevel Optimization Problems Using the {{KKT}} Approach},
  volume = {0},
  issn = {0233-1934},
  abstract = {Using the Karush\textendash{}Kuhn\textendash{}Tucker conditions for the convex lower level problem, the bilevel optimization problem is transformed into a single-level optimization problem (a mathematical program with complementarity constraints). A regularization approach for the latter problem is formulated which can be used to solve the bilevel optimization problem. This is verified if global or local optimal solutions of the auxiliary problems are computed. Stationary solutions of the auxiliary problems converge to C-stationary solutions of the mathematical program with complementarity constraints.},
  number = {0},
  journal = {Optimization},
  doi = {10.1080/02331934.2019.1581192},
  author = {Dempe, S. and Franke, S.},
  month = mar,
  year = {2019},
  keywords = {bilevel,Bilevel optimization,65K05,90C26,91A65,Karush–Kuhn–Tucker transformation,mathematical program with complementarity constraints},
  pages = {1-19},
  file = {/Users/markwang/drive/zotero/Dempe_Franke_2019_Solution of bilevel optimization problems using the KKT approach.pdf;/Users/markwang/Zotero/storage/62TTLCZ3/02331934.2019.html}
}

@article{ramanathDemosaickingMethodsBayer2002,
  title = {Demosaicking Methods for {{Bayer}} Color Arrays},
  volume = {11},
  abstract = {Digital Still Color Cameras sample the color spectrum using a monolithic array of color filters overlaid on a charge coupled device array such that each pixel samples only one color band. The resulting mosaic of color samples is processed to produce a high resolution color image such that the values of the color bands not sampled at a certain location are estimated from its neighbors. This process is often referred to as demosaicking. This paper introduces and compares a few commonly used demosaicking methods using error metrics like mean squared error in the RGB color space and perceived error in the CIELAB color space. \textcopyright{} 2002 SPIE and IS\&T.},
  journal = {J. Electronic Imaging},
  doi = {10.1117/1.1484495},
  author = {Ramanath, Rajeev and Snyder, Wesley E. and Bilbro, Griff L. and Sander, William A.},
  year = {2002},
  keywords = {Algorithm,Color image,Color space,Computability in Europe,Demosaicing,Experiment,Image resolution,Mean squared error,Nonlinear system,Norm (social),Pixel,XYZ file format},
  pages = {306-315},
  file = {/Users/markwang/drive/zotero/Ramanath et al_2002_Demosaicking methods for Bayer color arrays.pdf}
}

@article{narasimhanEnhancingResolutionMultiple2005,
  title = {Enhancing Resolution along Multiple Imaging Dimensions Using Assorted Pixels},
  volume = {27},
  issn = {0162-8828},
  abstract = {Multisampled imaging is a general framework for using pixels on an image detector to simultaneously sample multiple dimensions of imaging (space, time, spectrum, brightness, polarization, etc.). The mosaic of red, green, and blue spectral filters found in most solid-state color cameras is one example of multisampled imaging. We briefly describe how multisampling can be used to explore other dimensions of imaging. Once such an image is captured, smooth reconstructions along the individual dimensions can be obtained using standard interpolation algorithms. Typically, this results in a substantial reduction of resolution (and, hence, image quality). One can extract significantly greater resolution in each dimension by noting that the light fields associated with real scenes have enormous redundancies within them, causing different dimensions to be highly correlated. Hence, multisampled images can be better interpolated using local structural models that are learned offline from a diverse set of training images. The specific type of structural models we use are based on polynomial functions of measured image intensities. They are very effective as well as computationally efficient. We demonstrate the benefits of structural interpolation using three specific applications. These are 1) traditional color imaging with a mosaic of color filters, 2) high dynamic range monochrome imaging using a mosaic of exposure filters, and 3) high dynamic range color imaging using a mosaic of overlapping color and exposure filters.},
  number = {4},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  doi = {10.1109/TPAMI.2005.76},
  author = {Narasimhan, S. G. and Nayar, S. K.},
  month = apr,
  year = {2005},
  keywords = {Demosaicing,Image resolution,Pixel,Algorithms,Artificial Intelligence,assorted pixels,Bayer pattern.,Brightness,color,Color,Computer Graphics,Detectors,dynamic range,Dynamic range,Filters,image colour analysis,image enhancement,Image Enhancement,Image Interpretation; Computer-Assisted,image resolution,image sampling,image segmentation,Imaging; Three-Dimensional,Index Terms- Image formation,Information Storage and Retrieval,interpolation,Interpolation,learning,learning (artificial intelligence),multiple imaging dimensions,multisampled imaging,multisampling,Numerical Analysis; Computer-Assisted,Pattern Recognition; Automated,Polarization,range monochrome imaging,Reproducibility of Results,resolution,Sensitivity and Specificity,Signal Processing; Computer-Assisted,Solid state circuits,standard interpolation algorithms,structural models,Subtraction Technique},
  pages = {518-530},
  file = {/Users/markwang/drive/zotero/Narasimhan_Nayar_2005_Enhancing resolution along multiple imaging dimensions using assorted pixels.pdf;/Users/markwang/Zotero/storage/9HLBJLSW/1401906.html}
}

@inproceedings{malvarHighqualityLinearInterpolation2004,
  title = {High-Quality Linear Interpolation for Demosaicing of {{Bayer}}-Patterned Color Images},
  volume = {3},
  abstract = {This paper introduces a new interpolation technique for demosaicing of color images produced by single-CCD digital cameras. We show that the proposed simple linear filter can lead to an improvement in PSNR of over 5.5 dB when compared to bilinear demosaicing, and about 0.7 dB improvement in R and B interpolation when compared to a recently introduced linear interpolator. The proposed filter also outperforms most nonlinear demosaicing algorithms, without the artifacts due to nonlinear processing, and a much reduced computational complexity.},
  booktitle = {2004 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  doi = {10.1109/ICASSP.2004.1326587},
  author = {Malvar, H. S. and {Li-wei He} and Cutler, R.},
  month = may,
  year = {2004},
  keywords = {Demosaicing,Pixel,Color,image colour analysis,interpolation,Interpolation,Bayer-patterned color images,Charge coupled devices,color image linear interpolation,computational complexity reduction,Digital cameras,image demosaicing,image reconstruction,linear filter,Nonlinear filters,Optical films,Optical filters,Optical sensors,PSNR improvement,R/B interpolation,Sensor arrays,single-CCD digital cameras},
  pages = {iii-485},
  file = {/Users/markwang/drive/zotero/Malvar et al_2004_High-quality linear interpolation for demosaicing of Bayer-patterned color images.pdf;/Users/markwang/Zotero/storage/JJVX2MR6/1326587.html}
}

@article{chungColorDemosaicingUsing2006,
  title = {Color {{Demosaicing Using Variance}} of {{Color Differences}}},
  volume = {15},
  issn = {1057-7149},
  abstract = {This paper presents an adaptive demosaicing algorithm. Missing green samples are first estimated based on the variances of the color differences along different edge directions. The missing red and blue components are then estimated based on the interpolated green plane. This algorithm can effectively preserve the details in texture regions and, at the same time, it can significantly reduce the color artifacts. As compared with the latest demosaicing algorithms, the proposed algorithm produces the best average demosaicing performance both objectively and subjectively},
  number = {10},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2006.877521},
  author = {Chung, K.- and Chan, Y.-},
  month = oct,
  year = {2006},
  keywords = {Demosaicing,Algorithms,Color,image colour analysis,Image Enhancement,Image Interpretation; Computer-Assisted,Information Storage and Retrieval,interpolation,Interpolation,Digital cameras,Sensor arrays,adaptive demosaicing algorithm,Bayer sampling,color artifact reduction,color demosaicing,color difference variance,color filter array,Colorimetry,Costs,digital camera,Digital filters,edge directions,green plane interpolation,Heuristic algorithms,image denoising,Image sampling,Image sensors,image texture,missing blue component,missing green samples,missing red component,Signal processing algorithms,texture regions},
  pages = {2944-2955},
  file = {/Users/markwang/drive/zotero/Chung_Chan_2006_Color Demosaicing Using Variance of Color Differences.pdf;/Users/markwang/Zotero/storage/W9LQ366Q/1703585.html}
}

@book{liImageDemosaicingSystematic,
  title = {Image {{Demosaicing}}: {{A Systematic Survey}}},
  shorttitle = {Image {{Demosaicing}}},
  abstract = {Image demosaicing is a problem of interpolating full-resolution color images from so-called color-filter-array (CFA) samples. Among various CFA patterns, Bayer pattern has been the most popular choice and demosaicing of Bayer pattern has attracted renewed interest in recent years partially due to the increased availability of source codes/executables in response to the principle of ``reproducible research''. In this article, we provide a systematic survey of over seventy published works in this field since 1999 (complementary to previous reviews 22, 67). Our review attempts to address important issues to demosaicing and identify fundamental differences among competing approaches. Our findings suggest most existing works belong to the class of sequential demosaicing- i.e., luminance channel is interpolated first and then chrominance channels are reconstructed based on recovered luminance information. We report our comparative study results with a collection of eleven competing algorithms whose source codes or executables are provided by the authors. Our comparison is performed on two data sets: Kodak PhotoCD (popular choice) and IMAX high-quality images (more challenging). While most existing demosaicing algorithms achieve good performance on the Kodak data set, their performance on the IMAX one (images with varying-hue and high-saturation edges) degrades significantly. Such observation suggests the importance of properly addressing the issue of mismatch between assumed model and observation data in demosaicing, which calls for further investigation on issues such as model validation, test data selection and performance evaluation.},
  author = {Li, Xin and Gunturk, Bahadir and Zhang, Lei},
  keywords = {Demosaicing},
  file = {/Users/markwang/drive/zotero/Li et al_Image Demosaicing - A Systematic Survey.pdf;/Users/markwang/Zotero/storage/YXG8RSTP/summary.html}
}

@article{menonColorImageDemosaicking2011,
  title = {Color Image Demosaicking: {{An}} Overview},
  volume = {26},
  shorttitle = {Color Image Demosaicking},
  abstract = {Demosaicking is the process of reconstructing a full-resolution color image from the sampled data acquired by a digital camera that apply a color filter array to a single sensor. This paper discusses the need of a color filter array and presents a survey of several techniques proposed to demosaicking. A comparison between the different methods is also provided, discussing their performances.},
  journal = {Sig. Proc.: Image Comm.},
  doi = {10.1016/j.image.2011.04.003},
  author = {Menon, Daniele and Calvagno, Giancarlo},
  month = oct,
  year = {2011},
  keywords = {Demosaicing},
  pages = {518-533}
}

@article{khashabiJointDemosaicingDenoising2014,
  title = {Joint {{Demosaicing}} and {{Denoising}} via {{Learned Nonparametric Random Fields}}},
  volume = {23},
  issn = {1057-7149},
  abstract = {We introduce a machine learning approach to demosaicing, the reconstruction of color images from incomplete color filter array samples. There are two challenges to overcome by a demosaicing method: 1) it needs to model and respect the statistics of natural images in order to reconstruct natural looking images and 2) it should be able to perform well in the presence of noise. To facilitate an objective assessment of current methods, we introduce a public ground truth data set of natural images suitable for research in image demosaicing and denoising. We then use this large data set to develop a machine learning approach to demosaicing. Our proposed method addresses both demosaicing challenges by learning a statistical model of images and noise from hundreds of natural images. The resulting model performs simultaneous demosaicing and denoising. We show that the machine learning approach has a number of benefits: 1) the model is trained to directly optimize a user-specified performance measure such as peak signal-to-noise ratio (PSNR) or structural similarity; 2) we can handle novel color filter array layouts by retraining the model on such layouts; and 3) it outperforms the previous state-of-the-art, in some setups by 0.7-dB PSNR, faithfully reconstructing edges, textures, and smooth areas. Our results demonstrate that in demosaicing and related imaging applications, discriminatively trained machine learning models have the potential for peak performance at comparatively low engineering effort.},
  number = {12},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2014.2359774},
  author = {Khashabi, D. and Nowozin, S. and Jancsary, J. and Fitzgibbon, A. W.},
  month = dec,
  year = {2014},
  keywords = {Demosaicing,image colour analysis,Interpolation,learning (artificial intelligence),image demosaicing,image reconstruction,color filter array,image denoising,Arrays,Cameras,color images reconstruction,demosaicing method,denoising,Image color analysis,Image edge detection,Image Processing; Computer-Assisted,imaging applications,learned nonparametric random fields,machine learning approach,machine learning models,natural images statistics,Noise,Noise reduction,peak signal-to-noise ratio,PSNR,Regression Analysis,regression tree fields,Signal-To-Noise Ratio,statistical analysis,statistical model,Statistics; Nonparametric},
  pages = {4968-4981},
  file = {/Users/markwang/drive/zotero/Khashabi et al_2014_Joint Demosaicing and Denoising via Learned Nonparametric Random Fields.pdf;/Users/markwang/Zotero/storage/C549UW2J/6906294.html}
}

@article{chakrabartiRethinkingColorCameras2014,
  title = {Rethinking Color Cameras},
  abstract = {Digital color cameras make sub-sampled measurements of color at alternating pixel locations, and then ``demosaick'' these measurements to create full color images by up-sampling. This allows traditional cameras with restricted processing hardware to produce color images from a single shot, but it requires blocking a majority of the incident light and is prone to aliasing artifacts. In this paper, we introduce a computational approach to color photography, where the sampling pattern and reconstruction process are co-designed to enhance sharpness and photographic speed. The pattern is made predominantly panchromatic, thus avoiding excessive loss of light and aliasing of high spatial-frequency intensity variations. Color is sampled at a very sparse set of locations and then propagated throughout the image with guidance from the un-aliased luminance channel. Experimental results show that this approach often leads to significant reductions in noise and aliasing artifacts, especially in low-light conditions.},
  journal = {2014 IEEE International Conference on Computational Photography (ICCP)},
  doi = {10.1109/ICCPHOT.2014.6831801},
  author = {Chakrabarti, Ayan and Freeman, William T. and Zickler, Todd E.},
  year = {2014},
  keywords = {Demosaicing,Pixel,Color,Aliasing,Blocking (computing),Ray (optics),Sampling (signal processing),Sparse language,Sparse matrix},
  pages = {1-8},
  file = {/Users/markwang/drive/zotero/Chakrabarti et al_2014_Rethinking color cameras.pdf}
}

@article{heideFlexISPFlexibleCamera2014,
  title = {{{FlexISP}}: {{A Flexible Camera Image Processing Framework}}},
  volume = {33},
  issn = {0730-0301},
  shorttitle = {{{FlexISP}}},
  abstract = {Conventional pipelines for capturing, displaying, and storing images are usually defined as a series of cascaded modules, each responsible for addressing a particular problem. While this divide-and-conquer approach offers many benefits, it also introduces a cumulative error, as each step in the pipeline only considers the output of the previous step, not the original sensor data. We propose an end-to-end system that is aware of the camera and image model, enforces natural-image priors, while jointly accounting for common image processing steps like demosaicking, denoising, deconvolution, and so forth, all directly in a given output representation (e.g., YUV, DCT). Our system is flexible and we demonstrate it on regular Bayer images as well as images from custom sensors. In all cases, we achieve large improvements in image quality and signal reconstruction compared to state-of-the-art techniques. Finally, we show that our approach is capable of very efficiently handling high-resolution images, making even mobile implementations feasible.},
  number = {6},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/2661229.2661260},
  author = {Heide, Felix and Steinberger, Markus and Tsai, Yun-Ta and Rouf, Mushfiqur and Paj{\k{a}}k, Dawid and Reddy, Dikpal and Gallo, Orazio and Liu, Jing and Heidrich, Wolfgang and Egiazarian, Karen and Kautz, Jan and Pulli, Kari},
  month = nov,
  year = {2014},
  keywords = {image reconstruction,image processing},
  pages = {231:1--231:13},
  file = {/Users/markwang/drive/zotero/Heide et al_2014_FlexISP - A Flexible Camera Image Processing Framework.pdf}
}

@article{gharbiDeepJointDemosaicking2016,
  title = {Deep {{Joint Demosaicking}} and {{Denoising}}},
  volume = {35},
  issn = {0730-0301},
  abstract = {Demosaicking and denoising are the key first stages of the digital imaging pipeline but they are also a severely ill-posed problem that infers three color values per pixel from a single noisy measurement. Earlier methods rely on hand-crafted filters or priors and still exhibit disturbing visual artifacts in hard cases such as moir{\'e} or thin edges. We introduce a new data-driven approach for these challenges: we train a deep neural network on a large corpus of images instead of using hand-tuned filters. While deep learning has shown great success, its naive application using existing training datasets does not give satisfactory results for our problem because these datasets lack hard cases. To create a better training set, we present metrics to identify difficult patches and techniques for mining community photographs for such patches. Our experiments show that this network and training procedure outperform state-of-the-art both on noisy and noise-free data. Furthermore, our algorithm is an order of magnitude faster than the previous best performing techniques.},
  number = {6},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/2980179.2982399},
  author = {Gharbi, Micha{\"e}l and Chaurasia, Gaurav and Paris, Sylvain and Durand, Fr{\'e}do},
  month = nov,
  year = {2016},
  keywords = {Demosaicing,denoising,convolutional neural networks,data driven methods,deep learning,demosaicking},
  pages = {191:1--191:12},
  file = {/Users/markwang/drive/zotero/Gharbi et al_2016_Deep Joint Demosaicking and Denoising.pdf}
}

@article{klatzerLearningJointDemosaicing2016,
  title = {Learning Joint Demosaicing and Denoising Based on Sequential Energy Minimization},
  abstract = {Demosaicing is an important first step for color image acquisition. For practical reasons, demosaicing algorithms have to be both efficient and yield high quality results in the presence of noise. The demosaicing problem poses several challenges, e.g. zippering and false color artifacts as well as edge blur. In this work, we introduce a novel learning based method that can overcome these challenges. We formulate demosaicing as an image restoration problem and propose to learn efficient regularization inspired by a variational energy minimization framework that can be trained for different sensor layouts. Our algorithm performs joint demosaicing and denoising in close relation to the real physical mosaicing process on a camera sensor. This is achieved by learning a sequence of energy minimization problems composed of a set of RGB filters and corresponding activation functions. We evaluate our algorithm on the Microsoft Demosaicing data set in terms of peak signal to noise ratio (PSNR) and structured similarity index (SSIM). Our algorithm is highly efficient both in image quality and run time. We achieve an improvement of up to 2.6 dB over recent state-of-the-art algorithms.},
  journal = {2016 IEEE International Conference on Computational Photography (ICCP)},
  doi = {10.1109/ICCPHOT.2016.7492871},
  author = {Klatzer, Teresa and Hammernik, Kerstin and Kn{\"o}belreiter, Patrick and Pock, Thomas},
  year = {2016},
  keywords = {Algorithm,Color image,Demosaicing,Noise reduction,Activation function,Circuit restoration,Composite artifact colors,Convolution,Decibel,Display resolution,Edge enhancement,Energy minimization,Image quality,Image restoration,Image sensor,Matrix regularization,Microsoft Outlook for Mac,Peak signal-to-noise ratio,Run time (program lifecycle phase),Scene statistics,Structural similarity,Variational principle},
  pages = {1-11}
}

@article{kokkinosDeepImageDemosaicking2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.05215},
  primaryClass = {cs},
  title = {Deep {{Image Demosaicking}} Using a {{Cascade}} of {{Convolutional Residual Denoising Networks}}},
  abstract = {Demosaicking and denoising are among the most crucial steps of modern digital camera pipelines and their joint treatment is a highly ill-posed inverse problem where at-least two-thirds of the information are missing and the rest are corrupted by noise. This poses a great challenge in obtaining meaningful reconstructions and a special care for the efficient treatment of the problem is required. While there are several machine learning approaches that have been recently introduced to deal with joint image demosaicking-denoising, in this work we propose a novel deep learning architecture which is inspired by powerful classical image regularization methods and large-scale convex optimization techniques. Consequently, our derived network is more transparent and has a clear interpretation compared to alternative competitive deep learning approaches. Our extensive experiments demonstrate that our network outperforms any previous approaches on both noisy and noise-free data. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which also requires fewer trainable parameters than the current state-of-the-art deep network solution. Finally, we show that our network has the ability to generalize well even when it is trained on small datasets, while keeping the overall number of trainable parameters low.},
  journal = {arXiv:1803.05215 [cs]},
  author = {Kokkinos, Filippos and Lefkimmiatis, Stamatios},
  month = mar,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Kokkinos_Lefkimmiatis_2018_Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks.pdf;/Users/markwang/Zotero/storage/MKPEFIDA/1803.html}
}

@article{henzDeepJointDesign2018,
  title = {Deep {{Joint Design}} of {{Color Filter Arrays}} and {{Demosaicing}}},
  volume = {37},
  abstract = {We present a convolutional neural network architecture for performing joint design of color filter array (CFA) patterns and demosaicing. Our generic model allows the training of CFAs of arbitrary sizes, optimizing each color filter over the entire RGB color space. The patterns and algorithms produced by our method provide high-quality color reconstructions. We demonstrate the effectiveness of our approach by showing that its results achieve higher PSNR than the ones obtained with state-of-the-art techniques on all standard demosaicing datasets, both for noise-free and noisy scenarios. Our method can also be used to obtain demosaicing strategies for pre-defined CFAs, such as the Bayer pattern, for which our results also surpass even the demosaicing algorithms specifically designed for such a pattern.},
  journal = {Computer Graphics Forum},
  doi = {10.1111/cgf.13370},
  author = {Henz, Bernardo and S L Gastal, Eduardo and Oliveira, Manuel},
  month = may,
  year = {2018},
  file = {/Users/markwang/drive/zotero/Henz et al_2018_Deep Joint Design of Color Filter Arrays and Demosaicing.pdf}
}

@article{zhouDeepResidualNetwork2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.06573},
  primaryClass = {cs},
  title = {Deep {{Residual Network}} for {{Joint Demosaicing}} and {{Super}}-{{Resolution}}},
  abstract = {In digital photography, two image restoration tasks have been studied extensively and resolved independently: demosaicing and super-resolution. Both these tasks are related to resolution limitations of the camera. Performing super-resolution on a demosaiced images simply exacerbates the artifacts introduced by demosaicing. In this paper, we show that such accumulation of errors can be easily averted by jointly performing demosaicing and super-resolution. To this end, we propose a deep residual network for learning an end-to-end mapping between Bayer images and high-resolution images. By training on high-quality samples, our deep residual demosaicing and super-resolution network is able to recover high-quality super-resolved images from low-resolution Bayer mosaics in a single step without producing the artifacts common to such processing when the two operations are done separately. We perform extensive experiments to show that our deep residual network achieves demosaiced and super-resolved images that are superior to the state-of-the-art both qualitatively and in terms of PSNR and SSIM metrics.},
  journal = {arXiv:1802.06573 [cs]},
  author = {Zhou, Ruofan and Achanta, Radhakrishna and S{\"u}sstrunk, Sabine},
  month = feb,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Zhou et al_2018_Deep Residual Network for Joint Demosaicing and Super-Resolution.pdf;/Users/markwang/Zotero/storage/4CDJ5T7A/1802.html}
}

@article{syuLearningDeepConvolutional2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.03769},
  primaryClass = {cs},
  title = {Learning {{Deep Convolutional Networks}} for {{Demosaicing}}},
  abstract = {This paper presents a comprehensive study of applying the convolutional neural network (CNN) to solving the demosaicing problem. The paper presents two CNN models that learn end-to-end mappings between the mosaic samples and the original image patches with full information. In the case the Bayer color filter array (CFA) is used, an evaluation with ten competitive methods on popular benchmarks confirms that the data-driven, automatically learned features by the CNN models are very effective. Experiments show that the proposed CNN models can perform equally well in both the sRGB space and the linear space. It is also demonstrated that the CNN model can perform joint denoising and demosaicing. The CNN model is very flexible and can be easily adopted for demosaicing with any CFA design. We train CNN models for demosaicing with three different CFAs and obtain better results than existing methods. With the great flexibility to be coupled with any CFA, we present the first data-driven joint optimization of the CFA design and the demosaicing method using CNN. Experiments show that the combination of the automatically discovered CFA pattern and the automatically devised demosaicing method significantly outperforms the current best demosaicing results. Visual comparisons confirm that the proposed methods reduce more visual artifacts than existing methods. Finally, we show that the CNN model is also effective for the more general demosaicing problem with spatially varying exposure and color and can be used for taking images of higher dynamic ranges with a single shot. The proposed models and the thorough experiments together demonstrate that CNN is an effective and versatile tool for solving the demosaicing problem.},
  journal = {arXiv:1802.03769 [cs]},
  author = {Syu, Nai-Sheng and Chen, Yu-Sheng and Chuang, Yung-Yu},
  month = feb,
  year = {2018},
  keywords = {Demosaicing,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Syu et al_2018_Learning Deep Convolutional Networks for Demosaicing.pdf;/Users/markwang/Zotero/storage/MAWHH7R3/1802.html}
}

@article{rudinNonlinearTotalVariation1992,
  title = {Nonlinear Total Variation Based Noise Removal Algorithms},
  volume = {60},
  issn = {0167-2789},
  abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t \textrightarrow {$\infty$} the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.},
  number = {1},
  journal = {Physica D: Nonlinear Phenomena},
  doi = {10.1016/0167-2789(92)90242-F},
  author = {Rudin, Leonid I. and Osher, Stanley and Fatemi, Emad},
  month = nov,
  year = {1992},
  keywords = {denoising},
  pages = {259-268},
  file = {/Users/markwang/drive/zotero/Rudin et al_1992_Nonlinear total variation based noise removal algorithms.pdf;/Users/markwang/Zotero/storage/CVNSXIYP/016727899290242F.html}
}

@inproceedings{tomasiBilateralFilteringGray1998,
  title = {Bilateral Filtering for Gray and Color Images},
  abstract = {Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image.},
  booktitle = {Sixth {{International Conference}} on {{Computer Vision}} ({{IEEE Cat}}. {{No}}.{{98CH36271}})},
  doi = {10.1109/ICCV.1998.710815},
  author = {Tomasi, C. and Manduchi, R.},
  month = jan,
  year = {1998},
  keywords = {Pixel,Color,denoising,image processing,bilateral filtering,color images,colour vision,Computer science,computer vision,edges preservation,Filtering,geometric closeness,gray images,Humans,Imaging phantoms,Low pass filters,perceptual metric,phantom colors,photometric similarity,Photometry,Shape measurement,Smoothing methods},
  pages = {839-846},
  file = {/Users/markwang/drive/zotero/Tomasi_Manduchi_1998_Bilateral filtering for gray and color images.pdf;/Users/markwang/Zotero/storage/YICZC2ZI/710815.html}
}

@article{buadesNonlocalImageMovie2008,
  title = {Nonlocal {{Image}} and {{Movie Denoising}}},
  volume = {76},
  issn = {1573-1405},
  abstract = {Neighborhood filters are nonlocal image and movie filters which reduce the noise by averaging similar pixels. The first object of the paper is to present a unified theory of these filters and reliable criteria to compare them to other filter classes. A CCD noise model will be presented justifying the involvement of neighborhood filters. A classification of neighborhood filters will be proposed, including classical image and movie denoising methods and discussing further a recently introduced neighborhood filter, NL-means. In order to compare denoising methods three principles will be discussed. The first principle, ``method noise'', specifies that only noise must be removed from an image. A second principle will be introduced, ``noise to noise'', according to which a denoising method must transform a white noise into a white noise. Contrarily to ``method noise'', this principle, which characterizes artifact-free methods, eliminates any subjectivity and can be checked by mathematical arguments and Fourier analysis. ``Noise to noise'' will be proven to rule out most denoising methods, with the exception of neighborhood filters. This is why a third and new comparison principle, the ``statistical optimality'', is needed and will be introduced to compare the performance of all neighborhood filters. The three principles will be applied to compare ten different image and movie denoising methods. It will be first shown that only wavelet thresholding methods and NL-means give an acceptable method noise. Second, that neighborhood filters are the only ones to satisfy the ``noise to noise'' principle. Third, that among them NL-means is closest to statistical optimality. A particular attention will be paid to the application of the statistical optimality criterion for movie denoising methods. It will be pointed out that current movie denoising methods are motion compensated neighborhood filters. This amounts to say that they are neighborhood filters and that the ideal neighborhood of a pixel is its trajectory. Unfortunately the aperture problem makes it impossible to estimate ground true trajectories. It will be demonstrated that computing trajectories and restricting the neighborhood to them is harmful for denoising purposes and that space-time NL-means preserves more movie details.},
  language = {en},
  number = {2},
  journal = {International Journal of Computer Vision},
  doi = {10.1007/s11263-007-0052-1},
  author = {Buades, Antoni and Coll, Bartomeu and Morel, Jean-Michel},
  month = feb,
  year = {2008},
  keywords = {denoising,Image denoising,Motion estimation,Movie denoising},
  pages = {123-139},
  file = {/Users/markwang/drive/zotero/Buades et al_2008_Nonlocal Image and Movie Denoising.pdf}
}

@article{afonsoFastImageRecovery2010,
  title = {Fast {{Image Recovery Using Variable Splitting}} and {{Constrained Optimization}}},
  volume = {19},
  issn = {1057-7149},
  abstract = {We propose a new fast algorithm for solving one of the standard formulations of image restoration and reconstruction which consists of an unconstrained optimization problem where the objective includes anl2data-fidelity term and a nonsmooth regularizer. This formulation allows both wavelet-based (with orthogonal or frame-based representations) regularization or total-variation regularization. Our approach is based on a variable splitting to obtain an equivalent constrained optimization formulation, which is then addressed with an augmented Lagrangian method. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence has been proved. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is faster than the current state of the art methods.},
  number = {9},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2010.2047910},
  author = {Afonso, M. V. and {Bioucas-Dias}, J. M. and Figueiredo, M. A. T.},
  month = sep,
  year = {2010},
  keywords = {Image reconstruction,Inverse problems,Pixel,image reconstruction,Convolution,Image restoration,alternating direction multiplier method,Augmented Lagrangian,augmented Lagrangian method,compressive sensing,Constraint optimization,convergence,Convergence,convex optimization,equivalent constrained optimization formulation,fast image recovery,Fourier transforms,Image coding,image restoration,inverse problems,l2data-fidelity term,Lagrangian functions,nonsmooth regularizer,optimisation,total variation,total-variation regularization,unconstrained optimization problem,variable splitting,wavelet transforms,wavelet-based regularization,wavelets},
  pages = {2345-2356},
  file = {/Users/markwang/drive/zotero/Afonso et al_2010_Fast Image Recovery Using Variable Splitting and Constrained Optimization.pdf;/Users/markwang/Zotero/storage/3QS7U5L7/5445028.html}
}

@article{figueiredoRestorationPoissonianImages2010,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1001.2244},
  title = {Restoration of {{Poissonian Images Using Alternating Direction Optimization}}},
  volume = {19},
  issn = {1057-7149, 1941-0042},
  abstract = {Much research has been devoted to the problem of restoring Poissonian images, namely for medical and astronomical applications. However, the restoration of these images using state-of-the-art regularizers (such as those based on multiscale representations or total variation) is still an active research area, since the associated optimization problems are quite challenging. In this paper, we propose an approach to deconvolving Poissonian images, which is based on an alternating direction optimization method. The standard regularization (or maximum a posteriori) restoration criterion, which combines the Poisson log-likelihood with a (non-smooth) convex regularizer (log-prior), leads to hard optimization problems: the log-likelihood is non-quadratic and non-separable, the regularizer is non-smooth, and there is a non-negativity constraint. Using standard convex analysis tools, we present sufficient conditions for existence and uniqueness of solutions of these optimization problems, for several types of regularizers: total-variation, frame-based analysis, and frame-based synthesis. We attack these problems with an instance of the alternating direction method of multipliers (ADMM), which belongs to the family of augmented Lagrangian algorithms. We study sufficient conditions for convergence and show that these are satisfied, either under total-variation or frame-based (analysis and synthesis) regularization. The resulting algorithms are shown to outperform alternative state-of-the-art methods, both in terms of speed and restoration accuracy.},
  number = {12},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2010.2053941},
  author = {Figueiredo, M{\'a}rio A. T. and {Bioucas-Dias}, Jos{\'e} M.},
  month = dec,
  year = {2010},
  keywords = {admm,Mathematics - Optimization and Control,denoising,94A08; 47N10,Mathematics - Numerical Analysis},
  pages = {3133-3145},
  file = {/Users/markwang/drive/zotero/Figueiredo_Bioucas-Dias_2010_Restoration of Poissonian Images Using Alternating Direction Optimization.pdf;/Users/markwang/Zotero/storage/T7UBSIJC/1001.html}
}

@article{buadesReviewImageDenoising2005,
  title = {A {{Review}} of {{Image Denoising Algorithms}}, with a {{New One}}},
  volume = {4},
  issn = {1540-3459},
  abstract = {The search for efficient image denoising methods is still a valid challenge at the crossing of functional analysis and statistics. In spite of the sophistication of the recently proposed methods, most algorithms have not yet attained a desirable level of applicability. All show an outstanding performance when the image model corresponds to the algorithm assumptions but fail in general and create artifacts or remove image fine structures. The main focus of this paper is, first, to define a general mathematical and experimental methodology to compare and classify classical image denoising algorithms and, second, to propose a nonlocal means (NL-means) algorithm addressing the preservation of structure in a digital image. The mathematical analysis is based on the analysis of the "method noise," defined as the difference between a digital image and its denoised version. The NL-means algorithm is proven to be asymptotically optimal under a generic statistical image model. The denoising performance of all considered methods are compared in four ways; mathematical: asymptotic order of magnitude of the method noise under regularity assumptions; perceptual-mathematical: the algorithms artifacts and their explanation as a violation of the image model; quantitative experimental: by tables of L2  distances of the denoised version to the original image. The most powerful evaluation method seems, however, to be the visualization of the method noise on natural images. The more this method noise looks like a real white noise, the better the method.},
  number = {2},
  journal = {Multiscale Modeling \& Simulation},
  doi = {10.1137/040616024},
  author = {Buades, A. and Coll, B. and Morel, J.},
  month = jan,
  year = {2005},
  keywords = {review},
  pages = {490-530},
  file = {/Users/markwang/drive/zotero/Buades et al_2005_A Review of Image Denoising Algorithms, with a New One.pdf;/Users/markwang/Zotero/storage/QZZSJLZE/040616024.html}
}

@inproceedings{venkatakrishnanPlugandPlayPriorsModel2013,
  title = {Plug-and-{{Play}} Priors for Model Based Reconstruction},
  abstract = {Model-based reconstruction is a powerful framework for solving a variety of inverse problems in imaging. In recent years, enormous progress has been made in the problem of denoising, a special case of an inverse problem where the forward model is an identity operator. Similarly, great progress has been made in improving model-based inversion when the forward model corresponds to complex physical measurements in applications such as X-ray CT, electron-microscopy, MRI, and ultrasound, to name just a few. However, combining state-of-the-art denoising algorithms (i.e., prior models) with state-of-the-art inversion methods (i.e., forward models) has been a challenge for many reasons. In this paper, we propose a flexible framework that allows state-of-the-art forward models of imaging systems to be matched with state-of-the-art priors or denoising models. This framework, which we term as Plug-and-Play priors, has the advantage that it dramatically simplifies software integration, and moreover, it allows state-of-the-art denoising methods that have no known formulation as an optimization problem to be used. We demonstrate with some simple examples how Plug-and-Play priors can be used to mix and match a wide variety of existing denoising models with a tomographic forward model, thus greatly expanding the range of possible problem solutions.},
  booktitle = {2013 {{IEEE Global Conference}} on {{Signal}} and {{Information Processing}}},
  doi = {10.1109/GlobalSIP.2013.6737048},
  author = {Venkatakrishnan, S. V. and Bouman, C. A. and Wohlberg, B.},
  month = dec,
  year = {2013},
  keywords = {Image reconstruction,Inverse problems,optimization problem,image reconstruction,image denoising,Noise reduction,inverse problems,optimisation,Computational modeling,denoising models,imaging system forward models,model based reconstruction,Optimization,Phantoms,plug-and-play priors,software integration,tomographic forward model,Tomography},
  pages = {945-948},
  file = {/Users/markwang/drive/zotero/Venkatakrishnan et al_2013_Plug-and-Play priors for model based reconstruction.pdf;/Users/markwang/Zotero/storage/5442BBKX/6737048.html}
}

@article{liuProgressiveImageDenoising2014,
  title = {Progressive {{Image Denoising Through Hybrid Graph Laplacian Regularization}}: {{A Unified Framework}}},
  volume = {23},
  issn = {1057-7149},
  shorttitle = {Progressive {{Image Denoising Through Hybrid Graph Laplacian Regularization}}},
  abstract = {Recovering images from corrupted observations is necessary for many real-world applications. In this paper, we propose a unified framework to perform progressive image recovery based on hybrid graph Laplacian regularized regression. We first construct a multiscale representation of the target image by Laplacian pyramid, then progressively recover the degraded image in the scale space from coarse to fine so that the sharp edges and texture can be eventually recovered. On one hand, within each scale, a graph Laplacian regularization model represented by implicit kernel is learned, which simultaneously minimizes the least square error on the measured samples and preserves the geometrical structure of the image data space. In this procedure, the intrinsic manifold structure is explicitly considered using both measured and unmeasured samples, and the nonlocal self-similarity property is utilized as a fruitful resource for abstracting a priori knowledge of the images. On the other hand, between two successive scales, the proposed model is extended to a projected high-dimensional feature space through explicit kernel mapping to describe the interscale correlation, in which the local structure regularity is learned and propagated from coarser to finer scales. In this way, the proposed algorithm gradually recovers more and more image details and edges, which could not been recovered in previous scale. We test our algorithm on one typical image recovery task: impulse noise removal. Experimental results on benchmark test images demonstrate that the proposed method achieves better performance than state-of-the-art algorithms.},
  number = {4},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2014.2303638},
  author = {Liu, X. and Zhai, D. and Zhao, D. and Zhai, G. and Gao, W.},
  month = apr,
  year = {2014},
  keywords = {image denoising,Image edge detection,Noise,Image denoising,Correlation,corrupted observations,Data models,explicit kernel mapping,geometrical structure,graph Laplacian,graph theory,hybrid graph,image data space,image representation,implicit kernel,impulse noise,impulse noise removal,intrinsic manifold structure,Kernel,kernel theory,Laplace equations,Laplace transforms,Laplacian pyramid,Laplacian regularized regression,least square error,least squares approximations,local smoothness,multiscale image representation,Noise measurement,non-local self-similarity,nonlocal self-similarity property,progressive image denoising,progressive image recovery,projected high-dimensional feature space,real-world applications,regression analysis,scale space,sharp edges,unified framework},
  pages = {1491-1503},
  file = {/Users/markwang/drive/zotero/Liu et al_2014_Progressive Image Denoising Through Hybrid Graph Laplacian Regularization - A Unified Framework.pdf;/Users/markwang/Zotero/storage/BEH6IXHA/6728689.html}
}

@article{chanAlgorithmInducedPriorImage2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.00715},
  title = {Algorithm-{{Induced Prior}} for {{Image Restoration}}},
  volume = {abs/1602.00715},
  abstract = {This paper studies a type of image priors that are constructed implicitly through the alternating direction method of multiplier (ADMM) algorithm, called the algorithm-induced prior. Different from classical image priors which are defined before running the reconstruction algorithm, algorithm-induced priors are defined by the denoising procedure used to replace one of the two modules in the ADMM algorithm. Since such prior is not explicitly defined, analyzing the performance has been difficult in the past. 
Focusing on the class of symmetric smoothing filters, this paper presents an explicit expression of the prior induced by the ADMM algorithm. The new prior is reminiscent to the conventional graph Laplacian but with stronger reconstruction performance. It can also be shown that the overall reconstruction has an efficient closed-form implementation if the associated symmetric smoothing filter is low rank. The results are validated with experiments on image inpainting.},
  journal = {ArXiv},
  author = {Chan, Stanley H.},
  year = {2016},
  keywords = {Algorithm,Experiment,Noise reduction,Image restoration,Inpainting,Laplacian matrix,Optimization problem,Smoothing},
  file = {/Users/markwang/drive/zotero/Chan_2016_Algorithm-Induced Prior for Image Restoration.pdf}
}

@incollection{yangDeepADMMNetCompressive2016,
  title = {Deep {{ADMM}}-{{Net}} for {{Compressive Sensing MRI}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  author = {{yang}, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  pages = {10--18},
  file = {/Users/markwang/drive/zotero/yang et al_2016_Deep ADMM-Net for Compressive Sensing MRI.pdf;/Users/markwang/Zotero/storage/2KKE3C4G/6406-deep-admm-net-for-compressive-sensing-mri.html}
}

@article{chanPlugandPlayADMMImage2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.01710},
  primaryClass = {cs},
  title = {Plug-and-{{Play ADMM}} for {{Image Restoration}}: {{Fixed Point Convergence}} and {{Applications}}},
  shorttitle = {Plug-and-{{Play ADMM}} for {{Image Restoration}}},
  abstract = {Alternating direction method of multiplier (ADMM) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the ADMM algorithm is its modular structure which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the ADMM algorithm. Because of the plug-in nature, this type of ADMM algorithms is coined the name "Plug-and-Play ADMM". Plug-and-Play ADMM has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play ADMM uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play ADMM algorithm with provable fixed point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play ADMM converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on super-resolution and single-photon imaging. We compare Plug-and-Play ADMM with state-of-the-art algorithms in each problem type, and demonstrate promising experimental results of the algorithm.},
  journal = {arXiv:1605.01710 [cs]},
  author = {Chan, Stanley H. and Wang, Xiran and Elgendy, Omar A.},
  month = may,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Chan et al_2016_Plug-and-Play ADMM for Image Restoration - Fixed Point Convergence and Applications.pdf;/Users/markwang/Zotero/storage/XH9CR7Y7/1605.html}
}

@article{heideProxImaLEfficientImage2016,
  title = {{{ProxImaL}}: Efficient Image Optimization Using Proximal Algorithms},
  volume = {35},
  issn = {07300301},
  shorttitle = {{{ProxImaL}}},
  abstract = {Computational photography systems are becoming increasingly diverse, while computational resources\textemdash{}for example on mobile platforms\textemdash{}are rapidly increasing. As diverse as these camera systems may be, slightly different variants of the underlying image processing tasks, such as demosaicking, deconvolution, denoising, inpainting, image fusion, and alignment, are shared between all of these systems. Formal optimization methods have recently been demonstrated to achieve state-of-the-art quality for many of these applications. Unfortunately, different combinations of natural image priors and optimization algorithms may be optimal for different problems, and implementing and testing each combination is currently a time-consuming and error-prone process. ProxImaL is a domainspecific language and compiler for image optimization problems that makes it easy to experiment with different problem formulations and algorithm choices. The language uses proximal operators as the fundamental building blocks of a variety of linear and nonlinear image formation models and cost functions, advanced image priors, and noise models. The compiler intelligently chooses the best way to translate a problem formulation and choice of optimization algorithm into an efficient solver implementation. In applications to the image processing pipeline, deconvolution in the presence of Poisson-distributed shot noise, and burst denoising, we show that a few lines of ProxImaL code can generate highly efficient solvers that achieve state-of-the-art results. We also show applications to the nonlinear and nonconvex problem of phase retrieval.},
  language = {en},
  number = {4},
  journal = {ACM Transactions on Graphics},
  doi = {10.1145/2897824.2925875},
  author = {Heide, Felix and Diamond, Steven and Nie{\ss}ner, Matthias and {Ragan-Kelley}, Jonathan and Heidrich, Wolfgang and Wetzstein, Gordon},
  month = jul,
  year = {2016},
  pages = {1-15},
  file = {/Users/markwang/drive/zotero/Heide et al_2016_ProxImaL - efficient image optimization using proximal algorithms.pdf}
}

@article{zhangLearningDeepCNN2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03264},
  primaryClass = {cs},
  title = {Learning {{Deep CNN Denoiser Prior}} for {{Image Restoration}}},
  abstract = {Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.},
  journal = {arXiv:1704.03264 [cs]},
  author = {Zhang, Kai and Zuo, Wangmeng and Gu, Shuhang and Zhang, Lei},
  month = apr,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Zhang et al_2017_Learning Deep CNN Denoiser Prior for Image Restoration.pdf;/Users/markwang/Zotero/storage/26UVPKRU/1704.html}
}

@article{meinhardtLearningProximalOperators2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1704.03488},
  primaryClass = {cs},
  title = {Learning {{Proximal Operators}}: {{Using Denoising Networks}} for {{Regularizing Inverse Imaging Problems}}},
  shorttitle = {Learning {{Proximal Operators}}},
  abstract = {While variational methods have been among the most powerful tools for solving linear inverse problems in imaging, deep (convolutional) neural networks have recently taken the lead in many challenging benchmarks. A remaining drawback of deep learning approaches is their requirement for an expensive retraining whenever the specific problem, the noise level, noise type, or desired measure of fidelity changes. On the contrary, variational methods have a plug-and-play nature as they usually consist of separate data fidelity and regularization terms. In this paper we study the possibility of replacing the proximal operator of the regularization used in many convex energy minimization algorithms by a denoising neural network. The latter therefore serves as an implicit natural image prior, while the data term can still be chosen independently. Using a fixed denoising neural network in exemplary problems of image deconvolution with different blur kernels and image demosaicking, we obtain state-of-the-art reconstruction results. These indicate the high generalizability of our approach and a reduction of the need for problem-specific training. Additionally, we discuss novel results on the analysis of possible optimization algorithms to incorporate the network into, as well as the choices of algorithm parameters and their relation to the noise level the neural network is trained on.},
  journal = {arXiv:1704.03488 [cs]},
  author = {Meinhardt, Tim and Moeller, Michael and Hazirbas, Caner and Cremers, Daniel},
  month = apr,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Meinhardt et al_2017_Learning Proximal Operators - Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf;/Users/markwang/Zotero/storage/6XFSE8ET/1704.html}
}

@article{romanoLittleEngineThat2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.02862},
  primaryClass = {cs},
  title = {The {{Little Engine}} That {{Could}}: {{Regularization}} by {{Denoising}} ({{RED}})},
  shorttitle = {The {{Little Engine}} That {{Could}}},
  abstract = {Removal of noise from an image is an extensively studied problem in image processing. Indeed, the recent advent of sophisticated and highly effective denoising algorithms lead some to believe that existing methods are touching the ceiling in terms of noise removal performance. Can we leverage this impressive achievement to treat other tasks in image processing? Recent work has answered this question positively, in the form of the Plug-and-Play Prior (\$P\^3\$) method, showing that any inverse problem can be handled by sequentially applying image denoising steps. This relies heavily on the ADMM optimization technique in order to obtain this chained denoising interpretation. Is this the only way in which tasks in image processing can exploit the image denoising engine? In this paper we provide an alternative, more powerful and more flexible framework for achieving the same goal. As opposed to the \$P\^3\$ method, we offer Regularization by Denoising (RED): using the denoising engine in defining the regularization of the inverse problem. We propose an explicit image-adaptive Laplacian-based regularization functional, making the overall objective functional clearer and better defined. With a complete flexibility to choose the iterative optimization procedure for minimizing the above functional, RED is capable of incorporating any image denoising algorithm, treat general inverse problems very effectively, and is guaranteed to converge to the globally optimal result. We test this approach and demonstrate state-of-the-art results in the image deblurring and super-resolution problems.},
  journal = {arXiv:1611.02862 [cs]},
  author = {Romano, Yaniv and Elad, Michael and Milanfar, Peyman},
  month = nov,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Mathematics - Numerical Analysis},
  file = {/Users/markwang/drive/zotero/Romano et al_2016_The Little Engine that Could - Regularization by Denoising (RED).pdf;/Users/markwang/Zotero/storage/CBFJZZ2R/1611.html}
}

@incollection{yangProximalDehazeNetPrior2018,
  address = {{Cham}},
  title = {Proximal {{Dehaze}}-{{Net}}: {{A Prior Learning}}-{{Based Deep Network}} for {{Single Image Dehazing}}},
  volume = {11211},
  isbn = {978-3-030-01233-5 978-3-030-01234-2},
  shorttitle = {Proximal {{Dehaze}}-{{Net}}},
  abstract = {Photos taken in hazy weather are usually covered with white masks and often lose important details. In this paper, we propose a novel deep learning approach for single image dehazing by learning dark channel and transmission priors. First, we build an energy model for dehazing using dark channel and transmission priors and design an iterative optimization algorithm using proximal operators for these two priors. Second, we unfold the iterative algorithm to be a deep network, dubbed as proximal dehaze-net, by learning the proximal operators using convolutional neural networks. Our network combines the advantages of traditional prior-based dehazing methods and deep learning methods by incorporating haze-related prior learning into deep network. Experiments show that our method achieves state-of-the-art performance for single image dehazing.},
  language = {en},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  publisher = {{Springer International Publishing}},
  author = {Yang, Dong and Sun, Jian},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  pages = {729-746},
  file = {/Users/markwang/drive/zotero/Yang_Sun_2018_Proximal Dehaze-Net - A Prior Learning-Based Deep Network for Single Image Dehazing.pdf},
  doi = {10.1007/978-3-030-01234-2_43}
}

@article{reehorstRegularizationDenoisingClarifications2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.02296},
  primaryClass = {cs},
  title = {Regularization by {{Denoising}}: {{Clarifications}} and {{New Interpretations}}},
  shorttitle = {Regularization by {{Denoising}}},
  abstract = {Regularization by Denoising (RED), as recently proposed by Romano, Elad, and Milanfar, is powerful image-recovery framework that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function. Experimental evidence suggests that the RED algorithms are state-of-the-art. We claim, however, that explicit regularization does not explain the RED algorithms. In particular, we show that many of the expressions in the paper by Romano et al. hold only when the denoiser has a symmetric Jacobian, and we demonstrate that such symmetry does not occur with practical denoisers such as non-local means, BM3D, TNRD, and DnCNN. To explain the RED algorithms, we propose a new framework called Score-Matching by Denoising (SMD), which aims to match a "score" (i.e., the gradient of a log-prior). We then show tight connections between SMD, kernel density estimation, and constrained minimum mean-squared error denoising. Furthermore, we interpret the RED algorithms from Romano et al. and propose new algorithms with acceleration and convergence guarantees. Finally, we show that the RED algorithms seek a consensus equilibrium solution, which facilitates a comparison to plug-and-play ADMM.},
  journal = {arXiv:1806.02296 [cs]},
  author = {Reehorst, Edward T. and Schniter, Philip},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Reehorst_Schniter_2018_Regularization by Denoising - Clarifications and New Interpretations.pdf;/Users/markwang/Zotero/storage/JGU54Q6A/1806.html}
}

@article{sunBlockCoordinateRegularization2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.05113},
  primaryClass = {cs, eess},
  title = {Block {{Coordinate Regularization}} by {{Denoising}}},
  abstract = {We consider the problem of estimating a vector from its noisy measurements using a prior specified only through a denoising function. Recent work on plug-and-play priors (PnP) and regularization-by-denoising (RED) has shown the state-of-the-art performance of estimators under such priors in a range of imaging tasks. In this work, we develop a new block coordinate RED algorithm that decomposes a large-scale estimation problem into a sequence of updates over a small subset of the unknown variables. We theoretically analyze the convergence of the algorithm and discuss its relationship to the traditional proximal optimization. Our analysis complements and extends recent theoretical results for RED-based estimation methods. We numerically validate our method using several denoiser priors, including those based on convolutional neural network (CNN) denoisers.},
  journal = {arXiv:1905.05113 [cs, eess]},
  author = {Sun, Yu and Liu, Jiaming and Kamilov, Ulugbek S.},
  month = may,
  year = {2019},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/markwang/drive/zotero/Sun et al_2019_Block Coordinate Regularization by Denoising.pdf;/Users/markwang/Zotero/storage/N5Z3LHLF/1905.html}
}

@article{mataevDeepREDDeepImage2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1903.10176},
  primaryClass = {cs, eess},
  title = {{{DeepRED}}: {{Deep Image Prior Powered}} by {{RED}}},
  shorttitle = {{{DeepRED}}},
  abstract = {Inverse problems in imaging are extensively studied, with a variety of strategies, tools, and theory that have been accumulated over the years. Recently, this field has been immensely influenced by the emergence of deep-learning techniques. One such contribution, which is the focus of this paper, is the Deep Image Prior (DIP) work by Ulyanov, Vedaldi, and Lempitsky (2018). DIP offers a new approach towards the regularization of inverse problems, obtained by forcing the recovered image to be synthesized from a given deep architecture. While DIP has been shown to be effective, its results fall short when compared to state-of-the-art alternatives. In this work, we aim to boost DIP by adding an explicit prior, which enriches the overall regularization effect in order to lead to better-recovered images. More specifically, we propose to bring-in the concept of Regularization by Denoising (RED), which leverages existing denoisers for regularizing inverse problems. Our work shows how the two (DeepRED) can be merged to a highly effective recovery process while avoiding the need to differentiate the chosen denoiser, and leading to very effective results, demonstrated for several tested inverse problems.},
  journal = {arXiv:1903.10176 [cs, eess]},
  author = {Mataev, Gary and Elad, Michael and Milanfar, Peyman},
  month = mar,
  year = {2019},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/markwang/drive/zotero/Mataev et al_2019_DeepRED - Deep Image Prior Powered by RED.pdf;/Users/markwang/Zotero/storage/YRHRXUPH/1903.html}
}

@article{diamondUnrolledOptimizationDeep2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.08041},
  primaryClass = {cs},
  title = {Unrolled {{Optimization}} with {{Deep Priors}}},
  abstract = {A broad class of problems at the core of computational imaging, sensing, and low-level computer vision reduces to the inverse problem of extracting latent images that follow a prior distribution, from measurements taken under a known physical image formation model. Traditionally, hand-crafted priors along with iterative optimization methods have been used to solve such problems. In this paper we present unrolled optimization with deep priors, a principled framework for infusing knowledge of the image formation into deep networks that solve inverse problems in imaging, inspired by classical iterative methods. We show that instances of the framework outperform the state-of-the-art by a substantial margin for a wide variety of imaging problems, such as denoising, deblurring, and compressed sensing magnetic resonance imaging (MRI). Moreover, we conduct experiments that explain how the framework is best used and why it outperforms previous methods.},
  journal = {arXiv:1705.08041 [cs]},
  author = {Diamond, Steven and Sitzmann, Vincent and Heide, Felix and Wetzstein, Gordon},
  month = may,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Diamond et al_2017_Unrolled Optimization with Deep Priors.pdf;/Users/markwang/Zotero/storage/NN68YC3F/1705.html}
}

@article{salviPatternCodificationStrategies2004,
  series = {Agent {{Based Computer Vision}}},
  title = {Pattern Codification Strategies in Structured Light Systems},
  volume = {37},
  issn = {0031-3203},
  abstract = {Coded structured light is considered one of the most reliable techniques for recovering the surface of objects. This technique is based on projecting a light pattern and viewing the illuminated scene from one or more points of view. Since the pattern is coded, correspondences between image points and points of the projected pattern can be easily found. The decoded points can be triangulated and 3D information is obtained. We present an overview of the existing techniques, as well as a new and definitive classification of patterns for structured light sensors. We have implemented a set of representative techniques in this field and present some comparative results. The advantages and constraints of the different patterns are also discussed.},
  number = {4},
  journal = {Pattern Recognition},
  doi = {10.1016/j.patcog.2003.10.002},
  author = {Salvi, Joaquim and Pag{\`e}s, Jordi and Batlle, Joan},
  month = apr,
  year = {2004},
  keywords = {3D measuring devices,Active stereo,Coded patterns,Computer vision,Structured light},
  pages = {827-849},
  file = {/Users/markwang/drive/zotero/Salvi et al_2004_Pattern codification strategies in structured light systems.pdf;/Users/markwang/Zotero/storage/MWLFIADJ/S0031320303003303.html}
}

@inproceedings{guptaMicroPhaseShifting2012,
  address = {{Providence, RI}},
  title = {Micro {{Phase Shifting}}},
  isbn = {978-1-4673-1228-8 978-1-4673-1226-4 978-1-4673-1227-1},
  abstract = {We consider the problem of shape recovery for real world scenes, where a variety of global illumination (interreflections, subsurface scattering, etc.) and illumination defocus effects are present. These effects introduce systematic and often significant errors in the recovered shape. We introduce a structured light technique called Micro Phase Shifting, which overcomes these problems. The key idea is to project sinusoidal patterns with frequencies limited to a narrow, highfrequency band. These patterns produce a set of images over which global illumination and defocus effects remain constant for each point in the scene. This enables high quality reconstructions of scenes which have traditionally been considered hard, using only a small number of images. We also derive theoretical lower bounds on the number of input images needed for phase shifting and show that Micro PS achieves the bound.},
  language = {en},
  booktitle = {2012 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  publisher = {{IEEE}},
  doi = {10.1109/CVPR.2012.6247753},
  author = {Gupta, M. and Nayar, S. K.},
  month = jun,
  year = {2012},
  pages = {813-820},
  file = {/Users/markwang/drive/zotero/Gupta_Nayar_2012_Micro Phase Shifting.pdf}
}

@inproceedings{bougleuxDiscreteRegularizationWeighted2007,
  address = {{Ischia, Italy}},
  series = {{{LNCS}}},
  title = {Discrete {{Regularization}} on {{Weighted Graphs}} for {{Image}} and {{Mesh Filtering}}},
  volume = {4485},
  abstract = {We propose a discrete regularization framework on weighted graphs of arbitrary topology, which unifies image and mesh filtering. The approach considers the problem as a variational one, which consists in minimizing a weighted sum of two energy terms: a regularization one that uses the discrete p-Laplace operator, and an approximation one. This formulation leads to a family of simple nonlinear filters, parameterized by the degree p of smoothness and by the graph weight function. Some of these filters provide a graph-based version of well-known filters used in image and mesh processing, such as the bilateral filter, the TV digital filter or the nonlocal mean filter.},
  booktitle = {1st {{International Conference}} on {{Scale Space}} and {{Variational Methods}} in {{Computer Vision}} ({{SSVM}} 2007)},
  publisher = {{Springer}},
  doi = {10.1007/978-3-540-72823-8_12},
  author = {Bougleux, S{\'e}bastien and Elmoataz, Abderrahim and Melkemi, Mahmoud},
  month = may,
  year = {2007},
  pages = {128-139},
  file = {/Users/markwang/drive/zotero/Bougleux et al_2007_Discrete Regularization on Weighted Graphs for Image and Mesh Filtering.pdf}
}

@article{elmoatazNonlocalDiscreteRegularization2008,
  title = {Nonlocal {{Discrete Regularization}} on {{Weighted Graphs}}: {{A Framework}} for {{Image}} and {{Manifold Processing}}},
  volume = {17},
  issn = {1057-7149, 1941-0042},
  shorttitle = {Nonlocal {{Discrete Regularization}} on {{Weighted Graphs}}},
  abstract = {We introduce a nonlocal discrete regularization framework on weighted graphs of the arbitrary topologies for image and manifold processing. The approach considers the problem as a variational one, which consists in minimizing a weighted sum of two energy terms: a regularization one that uses a discrete weighted p-Dirichlet energy, and an approximation one. This is the discrete analogue of recent continuous Euclidean nonlocal regularization functionals. The proposed formulation leads to a family of simple and fast nonlinear processing methods based on the weighted p-Laplace operator, parameterized by the degree p of regularity, the graph structure and the graph weight function. These discrete processing methods provide a graph-based version of recently proposed semi-local or nonlocal processing methods used in image and mesh processing, such as the bilateral filter, the TV digital filter or the nonlocal means filter. It works with equal ease on regular 2D-3D images, manifolds or any data. We illustrate the abilities of the approach by applying it to various types of images, meshes, manifolds and data represented as graphs.},
  language = {en},
  number = {7},
  journal = {IEEE Transactions on Image Processing},
  doi = {10.1109/TIP.2008.924284},
  author = {Elmoataz, A. and Lezoray, O. and Bougleux, S.},
  month = jul,
  year = {2008},
  pages = {1047-1060},
  file = {/Users/markwang/drive/zotero/Elmoataz et al_2008_Nonlocal Discrete Regularization on Weighted Graphs - A Framework for Image and Manifold Processing.pdf}
}

@article{reuterDiscreteLaplaceBeltrami2009,
  series = {{{IEEE International Conference}} on {{Shape Modelling}} and {{Applications}} 2009},
  title = {Discrete {{Laplace}}\textendash{{Beltrami}} Operators for Shape Analysis and Segmentation},
  volume = {33},
  issn = {0097-8493},
  abstract = {Shape analysis plays a pivotal role in a large number of applications, ranging from traditional geometry processing to more recent 3D content management. In this scenario, spectral methods are extremely promising as they provide a natural library of tools for shape analysis, intrinsically defined by the shape itself. In particular, the eigenfunctions of the Laplace\textendash{}Beltrami operator yield a set of real-valued functions that provide interesting insights in the structure and morphology of the shape. In this paper, we first analyze different discretizations of the Laplace\textendash{}Beltrami operator (geometric Laplacians, linear and cubic FEM operators) in terms of the correctness of their eigenfunctions with respect to the continuous case. We then present the family of segmentations induced by the nodal sets of the eigenfunctions, discussing its meaningfulness for shape understanding.},
  number = {3},
  journal = {Computers \& Graphics},
  doi = {10.1016/j.cag.2009.03.005},
  author = {Reuter, Martin and Biasotti, Silvia and Giorgi, Daniela and Patan{\`e}, Giuseppe and Spagnuolo, Michela},
  month = jun,
  year = {2009},
  keywords = {Eigenfunctions,Laplace–Beltrami operator,Nodal domains,Nodal sets,Shape analysis,Shape segmentation},
  pages = {381-390},
  file = {/Users/markwang/drive/zotero/Reuter et al_2009_Discrete Laplace–Beltrami operators for shape analysis and segmentation.pdf;/Users/markwang/Zotero/storage/WF3IFBDE/S0097849309000272.html}
}

@inproceedings{wardetzkyDiscreteLaplaceOperators2008,
  address = {{Singapore}},
  title = {Discrete {{Laplace}} Operators: No Free Lunch},
  shorttitle = {Discrete {{Laplace}} Operators},
  abstract = {Discrete Laplace operators are ubiquitous in applications spanning geometric modeling to simulation. For robustness and efficiency, many applications require discrete operators that retain key structural properties inherent to the continuous setting. Building on the smooth setting, we present a set of natural properties for discrete Laplace operators for triangular surface meshes. We prove an important theoretical limitation: discrete Laplacians cannot satisfy all natural properties; retroactively, this explains the diversity of existing discrete Laplace operators. Finally, we present a family of operators that includes and extends well-known and widely-used operators.},
  language = {en},
  booktitle = {{{ACM SIGGRAPH ASIA}} 2008 Courses on - {{SIGGRAPH Asia}} '08},
  publisher = {{ACM Press}},
  doi = {10.1145/1508044.1508063},
  author = {Wardetzky, Max and Mathur, Saurabh and K{\"a}lberer, Felix and Grinspun, Eitan},
  year = {2008},
  pages = {1-5},
  file = {/Users/markwang/drive/zotero/Wardetzky et al_2008_Discrete Laplace operators - no free lunch.pdf}
}

@article{sitzmannEndtoendOptimizationOptics2018,
  title = {End-to-End {{Optimization}} of {{Optics}} and {{Image Processing}} for {{Achromatic Extended Depth}} of {{Field}} and {{Super}}-Resolution {{Imaging}}},
  volume = {37},
  issn = {0730-0301},
  abstract = {In typical cameras the optical system is designed first; once it is fixed, the parameters in the image processing algorithm are tuned to get good image reproduction. In contrast to this sequential design approach, we consider joint optimization of an optical system (for example, the physical shape of the lens) together with the parameters of the reconstruction algorithm. We build a fully-differentiable simulation model that maps the true source image to the reconstructed one. The model includes diffractive light propagation, depth and wavelength-dependent effects, noise and nonlinearities, and the image post-processing. We jointly optimize the optical parameters and the image processing algorithm parameters so as to minimize the deviation between the true and reconstructed image, over a large set of images. We implement our joint optimization method using autodifferentiation to efficiently compute parameter gradients in a stochastic optimization algorithm. We demonstrate the efficacy of this approach by applying it to achromatic extended depth of field and snapshot super-resolution imaging.},
  number = {4},
  journal = {ACM Trans. Graph.},
  doi = {10.1145/3197517.3201333},
  author = {Sitzmann, Vincent and Diamond, Steven and Peng, Yifan and Dun, Xiong and Boyd, Stephen and Heidrich, Wolfgang and Heide, Felix and Wetzstein, Gordon},
  month = jul,
  year = {2018},
  keywords = {computational,optics},
  pages = {114:1--114:13},
  file = {/Users/markwang/drive/zotero/Sitzmann et al_2018_End-to-end Optimization of Optics and Image Processing for Achromatic Extended Depth of Field and Super-resolution Imaging.pdf}
}

@inproceedings{rothFieldsExpertsFramework2005,
  address = {{San Diego, CA, USA}},
  title = {Fields of {{Experts}}: {{A Framework}} for {{Learning Image Priors}}},
  volume = {2},
  isbn = {978-0-7695-2372-9},
  shorttitle = {Fields of {{Experts}}},
  abstract = {We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov Random Field (MRF) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear filter responses. In contrast to previous MRF approaches all parameters, including the linear filters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a specific application, we obtain results that compete with and even outperform specialized techniques.},
  language = {en},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  publisher = {{IEEE}},
  doi = {10.1109/CVPR.2005.160},
  author = {Roth, S. and Black, M.J.},
  year = {2005},
  pages = {860-867},
  file = {/Users/markwang/drive/zotero/Roth_Black_2005_Fields of Experts - A Framework for Learning Image Priors.pdf}
}

@article{gregorLearningFastApproximations,
  title = {Learning {{Fast Approximations}} of {{Sparse Coding}}},
  abstract = {In Sparse Coding (SC), input vectors are reconstructed using a sparse linear combination of basis vectors. SC has become a popular method for extracting features from data. For a given input, SC minimizes a quadratic reconstruction error with an L1 penalty term on the code. The process is often too slow for applications such as real-time pattern recognition. We proposed two versions of a very fast algorithm that produces approximate estimates of the sparse code that can be used to compute good visual features, or to initialize exact iterative algorithms. The main idea is to train a non-linear, feed-forward predictor with a specific architecture and a fixed depth to produce the best possible approximation of the sparse code. A version of the method, which can be seen as a trainable version of Li and Osher's coordinate descent method, is shown to produce approximate solutions with 10 times less computation than Li and Osher's for the same approximation error. Unlike previous proposals for sparse code predictors, the system allows a kind of approximate ``explaining away'' to take place during inference. The resulting predictor is differentiable and can be included into globallytrained recognition systems.},
  language = {en},
  author = {Gregor, Karol and LeCun, Yann},
  pages = {8},
  file = {/Users/markwang/drive/zotero/Gregor_LeCun_Learning Fast Approximations of Sparse Coding.pdf}
}

@article{donohoOptimallySparseRepresentation2003,
  title = {Optimally Sparse Representation in General (Nonorthogonal) Dictionaries via {$\mathscr{l}$}1 Minimization},
  volume = {100},
  copyright = {Copyright \textcopyright{} 2003, The National Academy of Sciences},
  issn = {0027-8424, 1091-6490},
  abstract = {Given a dictionary D = \{dk\} of vectors dk, we seek to represent a signal S as a linear combination S = {$\sum$}k {$\gamma$}(k)dk, with scalar coefficients {$\gamma$}(k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the {$\mathscr{l}$}1 norm of the coefficients {$\gamma\underbar$}. In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.},
  language = {en},
  number = {5},
  journal = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0437847100},
  author = {Donoho, David L. and Elad, Michael},
  month = mar,
  year = {2003},
  pages = {2197-2202},
  file = {/Users/markwang/drive/zotero/Donoho_Elad_2003_Optimally sparse representation in general (nonorthogonal) dictionaries via ℓ1 minimization.pdf;/Users/markwang/Zotero/storage/M9BQR9UM/2197.html},
  pmid = {16576749}
}

@inproceedings{beckFastIterativeShrinkageThresholding2009,
  title = {A Fast {{Iterative Shrinkage}}-{{Thresholding Algorithm}} with Application to Wavelet-Based Image Deblurring},
  abstract = {We consider the class of Iterative Shrinkage-Thresholding Algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods is attractive due to its simplicity, however, they are also known to converge quite slowly. In this paper we present a Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) which preserves the computational simplicity of ISTA, but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA.},
  booktitle = {2009 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  doi = {10.1109/ICASSP.2009.4959678},
  author = {Beck, A. and Teboulle, M.},
  month = apr,
  year = {2009},
  keywords = {Inverse problems,Signal processing algorithms,Image restoration,Convergence,image restoration,wavelet transforms,Acceleration,fast iterative shrinkage-thresholding algorithm,image deblurring,Iterative algorithms,iterative methods,Iterative methods,iterative shrinkage-thresholding algorithm,least squares,least squares and l1 regularization problems,Least squares approximation,optimal gradient method,Signal processing,signal/image processing,Sparse matrices,two steps iterative algorithms,wavelet-based image deblurring},
  pages = {693-696},
  file = {/Users/markwang/drive/zotero/Beck_Teboulle_2009_A fast Iterative Shrinkage-Thresholding Algorithm with application to wavelet-based image deblurring.pdf;/Users/markwang/Zotero/storage/FF3BVFTM/4959678.html}
}

@article{mardaniNeuralProximalGradient2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.03963},
  primaryClass = {cs},
  title = {Neural {{Proximal Gradient Descent}} for {{Compressive Imaging}}},
  abstract = {Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. Learning a good inverse mapping from training data faces severe challenges, including: (i) scarcity of training data; (ii) need for plausible reconstructions that are physically feasible; (iii) need for fast reconstruction, especially in real-time applications. We develop a successful system solving all these challenges, using as basic architecture the recurrent application of proximal gradient algorithm. We learn a proximal map that works well with real images based on residual networks. Contraction of the resulting map is analyzed, and incoherence conditions are investigated that drive the convergence of the iterates. Extensive experiments are carried out under different settings: (a) reconstructing abdominal MRI of pediatric patients from highly undersampled Fourier-space data and (b) superresolving natural face images. Our key findings include: 1. a recurrent ResNet with a single residual block unrolled from an iterative algorithm yields an effective proximal which accurately reveals MR image details. 2. Our architecture significantly outperforms conventional non-recurrent deep ResNets by 2dB SNR; it is also trained much more rapidly. 3. It outperforms state-of-the-art compressed-sensing Wavelet-based methods by 4dB SNR, with 100x speedups in reconstruction time.},
  journal = {arXiv:1806.03963 [cs]},
  author = {Mardani, Morteza and Sun, Qingyun and Vasawanala, Shreyas and Papyan, Vardan and Monajemi, Hatef and Pauly, John and Donoho, David},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Machine Learning,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Mardani et al_2018_Neural Proximal Gradient Descent for Compressive Imaging.pdf;/Users/markwang/Zotero/storage/EQI724KX/1806.html}
}

@inproceedings{aggarwalModelBasedImage2018,
  title = {Model Based Image Reconstruction Using Deep Learned Priors ({{MODL}})},
  abstract = {We introduce a model-based image reconstruction framework, where we use a deep convolution neural network (CNN) based regularization prior. We rely on a recursive algorithm, which alternates between a CNN based denoising step and enforcement of data consistency. Unrolling the recursive algorithm yields a deep network that is trained using backpropagation. The unique aspect of this method is the use of the same CNN weights at each iteration, which makes the resulting structure consistent with the model-based formulation. Also, this approach reduces the number of trainable parameters, which hence lower the amount of training data needed. The use of a forward model also reduces the size of the network and enables the exploitation additional prior information available from calibration data. The use of the framework for multichannel MRI reconstruction provides improved reconstructions, compared to other state-of-the-art methods.},
  booktitle = {2018 {{IEEE}} 15th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2018)},
  doi = {10.1109/ISBI.2018.8363663},
  author = {Aggarwal, H. K. and Mani, M. P. and Jacob, M.},
  month = apr,
  year = {2018},
  keywords = {Image reconstruction,image reconstruction,image denoising,Noise reduction,Data models,iterative methods,backpropagation,calibration data,CNN based denoising step,CNN based regularization prior,CNN weights,Computer architecture,convolutional neural network,data consistency,deep convolution neural network,Deep learning,deep network,forward model,image reconstruction framework,Magnetic resonance imaging,model based image reconstruction using deep learned priors,multichannel MRI reconstruction,neural nets,parallel imaging,recursive algorithm,Sensitivity,Training,training data},
  pages = {671-674},
  file = {/Users/markwang/drive/zotero/Aggarwal et al_2018_Model based image reconstruction using deep learned priors (MODL).pdf;/Users/markwang/Zotero/storage/Z7FKX233/8363663.html}
}

@article{zhangISTANetInterpretableOptimizationInspired2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07929},
  primaryClass = {cs},
  title = {{{ISTA}}-{{Net}}: {{Interpretable Optimization}}-{{Inspired Deep Network}} for {{Image Compressive Sensing}}},
  shorttitle = {{{ISTA}}-{{Net}}},
  abstract = {With the aim of developing a fast yet accurate algorithm for compressive sensing (CS) reconstruction of natural images, we combine in this paper the merits of two existing categories of CS methods: the structure insights of traditional optimization-based methods and the speed of recent network-based ones. Specifically, we propose a novel structured deep network, dubbed ISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm (ISTA) for optimizing a general \$\textbackslash{}ell\_1\$ norm CS reconstruction model. To cast ISTA into deep network form, we develop an effective strategy to solve the proximal mapping associated with the sparsity-inducing regularizer using nonlinear transforms. All the parameters in ISTA-Net (\textbackslash{}eg nonlinear transforms, shrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than being hand-crafted. Moreover, considering that the residuals of natural images are more compressible, an enhanced version of ISTA-Net in the residual domain, dubbed \{ISTA-Net\}\$\^+\$, is derived to further improve CS reconstruction. Extensive CS experiments demonstrate that the proposed ISTA-Nets outperform existing state-of-the-art optimization-based and network-based CS methods by large margins, while maintaining fast computational speed. Our source codes are available: \textbackslash{}textsl\{http://jianzhang.tech/projects/ISTA-Net\}.},
  journal = {arXiv:1706.07929 [cs]},
  author = {Zhang, Jian and Ghanem, Bernard},
  month = jun,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Multimedia},
  file = {/Users/markwang/drive/zotero/Zhang_Ghanem_2017_ISTA-Net - Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing.pdf;/Users/markwang/Zotero/storage/IE4JDB94/1706.html}
}

@article{heDeepResidualLearning2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  primaryClass = {cs},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  journal = {arXiv:1512.03385 [cs]},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  month = dec,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/He et al_2015_Deep Residual Learning for Image Recognition.pdf;/Users/markwang/Zotero/storage/NGHW8XEH/1512.html}
}

@article{yangADMMNetDeepLearning2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.06869},
  primaryClass = {cs},
  title = {{{ADMM}}-{{Net}}: {{A Deep Learning Approach}} for {{Compressive Sensing MRI}}},
  shorttitle = {{{ADMM}}-{{Net}}},
  abstract = {Compressive sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR images from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and speed, in this paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and generalized versions. ADMM-Nets are defined over data flow graphs, which are derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They take the sampled k-space data as inputs and output reconstructed MR images. Moreover, we extend our network to cope with complex-valued MR images. In the training phase, all parameters of the nets, e.g., transforms, shrinkage functions, etc., are discriminatively trained end-to-end. In the testing phase, they have computational overhead similar to ADMM algorithm but use optimized parameters learned from the data for CS-based reconstruction task. We investigate different configurations in network structures and conduct extensive experiments on MR image reconstruction under different sampling rates. Due to the combination of the advantages in model-based approach and deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction accuracies with fast computational speed.},
  journal = {arXiv:1705.06869 [cs]},
  author = {Yang, Yan and Sun, Jian and Li, Huibin and Xu, Zongben},
  month = may,
  year = {2017},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/markwang/drive/zotero/Yang et al_2017_ADMM-Net - A Deep Learning Approach for Compressive Sensing MRI.pdf;/Users/markwang/Zotero/storage/BXBYGUTH/1705.html}
}

@article{xieDifferentiableLinearizedADMM2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.06179},
  primaryClass = {cs, stat},
  title = {Differentiable {{Linearized ADMM}}},
  abstract = {Recently, a number of learning-based optimization methods that combine data-driven architectures with the classical optimization algorithms have been proposed and explored, showing superior empirical performance in solving various ill-posed inverse problems, but there is still a scarcity of rigorous analysis about the convergence behaviors of learning-based optimization. In particular, most existing analyses are specific to unconstrained problems but cannot apply to the more general cases where some variables of interest are subject to certain constraints. In this paper, we propose Differentiable Linearized ADMM (D-LADMM) for solving the problems with linear constraints. Specifically, D-LADMM is a K-layer LADMM inspired deep neural network, which is obtained by firstly introducing some learnable weights in the classical Linearized ADMM algorithm and then generalizing the proximal operator to some learnable activation function. Notably, we rigorously prove that there exist a set of learnable parameters for D-LADMM to generate globally converged solutions, and we show that those desired parameters can be attained by training D-LADMM in a proper way. To the best of our knowledge, we are the first to provide the convergence analysis for the learning-based optimization method on constrained problems.},
  journal = {arXiv:1905.06179 [cs, stat]},
  author = {Xie, Xingyu and Wu, Jianlong and Zhong, Zhisheng and Liu, Guangcan and Lin, Zhouchen},
  month = may,
  year = {2019},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/markwang/drive/zotero/Xie et al_2019_Differentiable Linearized ADMM.pdf;/Users/markwang/Zotero/storage/BB6PIWRK/1905.html}
}

@inproceedings{liuALISTAAnalyticWeights2019,
  title = {{{ALISTA}}: {{Analytic Weights Are As Good As Learned Weights}} in {{LISTA}}},
  shorttitle = {{{ALISTA}}},
  abstract = {Deep neural networks based on unfolding an iterative algorithm, for example, LISTA (learned iterative shrinkage thresholding algorithm), have been an empirical success for sparse signal recovery. The weights of these neural networks are currently determined by data-driven ``black-box'' training. In this work, we propose Analytic LISTA (ALISTA), where the weight matrix in LISTA is computed as the solution to a data-free optimization problem, leaving only the stepsize and threshold parameters to data-driven learning. This significantly simplifies the training. Specifically, the data-free optimization problem is based on coherence minimization. We show our ALISTA retains the optimal linear convergence proved in (Chen et al., 2018) and has a performance comparable to LISTA. Furthermore, we extend ALISTA to convolutional linear operators, again determined in a data-free manner. We also propose a feed-forward framework that combines the data-free optimization and ALISTA networks from end to end, one that can be jointly trained to gain robustness to small perturbations in the encoding model.},
  booktitle = {{{ICLR}} 2019},
  author = {Liu, Jialin and Chen, Xiaohan and Wang, Zhangyang and Yin, Wotao},
  year = {2019},
  keywords = {Algorithm,Sparse matrix,Optimization problem,Artificial neural network,Black box,Detection theory,Entity–relationship model,Iterative method,Mathematical optimization,Neural Network Simulation,Perturbation theory,Rate of convergence,Unfolding (DSP implementation),Weight},
  file = {/Users/markwang/drive/zotero/Liu et al_2019_ALISTA - Analytic Weights Are As Good As Learned Weights in LISTA.pdf}
}

@inproceedings{ryuPlugandPlayMethodsProvably2019,
  title = {Plug-and-{{Play Methods Provably Converge}} with {{Properly Trained Denoisers}}},
  abstract = {Plug-and-play (PnP) is a non-convex framework that integrates modern denoising priors, such as BM3D or deep learning-based denoisers, into ADMM or other proximal algorithms. An advantage of PnP is ...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Ryu, Ernest and Liu, Jialin and Wang, Sicheng and Chen, Xiaohan and Wang, Zhangyang and Yin, Wotao},
  month = may,
  year = {2019},
  pages = {5546-5557},
  file = {/Users/markwang/drive/zotero/Ryu et al_2019_Plug-and-Play Methods Provably Converge with Properly Trained Denoisers.pdf;/Users/markwang/Zotero/storage/A7GP4L26/ryu19a.html}
}

@article{miyatoSpectralNormalizationGenerative2018,
  title = {Spectral {{Normalization}} for {{Generative Adversarial Networks}}},
  abstract = {One of the challenges in the study of generative adversarial networks is the instability of its training. 
  In this paper, we propose a novel weight normalization technique called spectral...},
  author = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  month = feb,
  year = {2018},
  file = {/Users/markwang/Zotero/storage/2G42QV7Q/Miyato et al. - 2018 - Spectral Normalization for Generative Adversarial .pdf;/Users/markwang/Zotero/storage/PBEPIXUX/forum.html}
}

@article{salimansImprovedTechniquesTraining2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1606.03498},
  primaryClass = {cs},
  title = {Improved {{Techniques}} for {{Training GANs}}},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  journal = {arXiv:1606.03498 [cs]},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  month = jun,
  year = {2016},
  keywords = {Computer Science - Machine Learning,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/markwang/Zotero/storage/JSIWSKKI/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf;/Users/markwang/Zotero/storage/6PSB3X2C/1606.html}
}

@article{ronnebergerUNetConvolutionalNetworks2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.04597},
  primaryClass = {cs},
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  journal = {arXiv:1505.04597 [cs]},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  month = may,
  year = {2015},
  file = {/Users/markwang/drive/zotero/Ronneberger et al_2015_U-Net - Convolutional Networks for Biomedical Image Segmentation.pdf;/Users/markwang/Zotero/storage/CEJRN3KZ/1505.html}
}


