
@article{liuInvestigatingTaskdrivenLatent2019,
	title = {Investigating Task-driven Latent Feasibility for Nonconvex Image Modeling},
	url = {http://arxiv.org/abs/1910.08242},
	abstract = {Properly modeling the latent image distributions always plays a key role in a variety of low-level vision problems. Most existing approaches, such as Maximum A Posterior ({MAP}), aimed at establishing optimization models with prior regularization to address this task. However, designing sophisticated priors may lead to challenging optimization model and time-consuming iteration process. Recent studies tried to embed learnable network architectures into the {MAP} scheme. Unfortunately, for the {MAP} model with deeply trained priors, the exact behaviors and the inference process are actually hard to investigate, due to their inexact and uncontrolled nature. In this work, by investigating task-driven latent feasibility for the {MAP}-based model, we provide a new perspective to enforce domain knowledge and data distributions to {MAP}-based image modeling. Specifically, we first introduce an energy-based feasibility constraint to the given {MAP} model. By introducing the proximal gradient updating scheme to the objective and performing an adaptive averaging process, we obtain a completely new {MAP} inference process, named Proximal Average Optimization ({PAO}), for image modeling. Owning to the flexibility of {PAO}, we can also incorporate deeply trained architectures into the feasibility module. Finally, we provide a simple monotone descent-based control mechanism to guide the propagation of {PAO}. We prove in theory that the sequence generated by both our {PAO} and its learning-based extension can successfully converge to the critical point of the original {MAP} optimization task. We demonstrate how to apply our framework to address different vision applications. Extensive experiments verify the theoretical results and show the advantages of our method against existing state-of-the-art approaches.},
	journaltitle = {{arXiv}:1910.08242 [cs]},
	author = {Liu, Risheng and Mu, Pan and Chen, Jian and Fan, Xin and Luo, Zhongxuan},
	urldate = {2019-11-12},
	date = {2019-10-17},
	eprinttype = {arxiv},
	eprint = {1910.08242},
	keywords = {tbr},
	file = {Liu et al_2019_Investigating Task-driven Latent Feasibility for Nonconvex Image Modeling.pdf:/Users/wpq/Dropbox (MIT)/zotero/Liu et al_2019_Investigating Task-driven Latent Feasibility for Nonconvex Image Modeling.pdf:application/pdf}
}

@article{liuRankMinimizationSnapshot2019,
	title = {Rank Minimization for Snapshot Compressive Imaging},
	volume = {41},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/1807.07837},
	doi = {10.1109/TPAMI.2018.2873587},
	abstract = {Snapshot compressive imaging ({SCI}) refers to compressive imaging systems where multiple frames are mapped into a single measurement, with video compressive imaging and hyperspectral compressive imaging as two representative applications. Though exciting results of high-speed videos and hyperspectral images have been demonstrated, the poor reconstruction quality precludes {SCI} from wide applications.This paper aims to boost the reconstruction quality of {SCI} via exploiting the high-dimensional structure in the desired signal. We build a joint model to integrate the nonlocal self-similarity of video/hyperspectral frames and the rank minimization approach with the {SCI} sensing process. Following this, an alternating minimization algorithm is developed to solve this non-convex problem. We further investigate the special structure of the sampling process in {SCI} to tackle the computational workload and memory issues in {SCI} reconstruction. Both simulation and real data (captured by four different {SCI} cameras) results demonstrate that our proposed algorithm leads to significant improvements compared with current state-of-the-art algorithms. We hope our results will encourage the researchers and engineers to pursue further in compressive imaging for real applications.},
	pages = {2990--3006},
	number = {12},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Liu, Yang and Yuan, Xin and Suo, Jinli and Brady, David J. and Dai, Qionghai},
	urldate = {2019-11-08},
	date = {2019-12-01},
	eprinttype = {arxiv},
	eprint = {1807.07837},
	keywords = {read},
	file = {Liu et al_2019_Rank Minimization for Snapshot Compressive Imaging.pdf:/Users/wpq/Dropbox (MIT)/zotero/Liu et al_2019_Rank Minimization for Snapshot Compressive Imaging.pdf:application/pdf}
}

@article{diamondUnrolledOptimizationDeep2017,
	title = {Unrolled Optimization with Deep Priors},
	url = {http://arxiv.org/abs/1705.08041},
	abstract = {A broad class of problems at the core of computational imaging, sensing, and low-level computer vision reduces to the inverse problem of extracting latent images that follow a prior distribution, from measurements taken under a known physical image formation model. Traditionally, hand-crafted priors along with iterative optimization methods have been used to solve such problems. In this paper we present unrolled optimization with deep priors, a principled framework for infusing knowledge of the image formation into deep networks that solve inverse problems in imaging, inspired by classical iterative methods. We show that instances of the framework outperform the state-of-the-art by a substantial margin for a wide variety of imaging problems, such as denoising, deblurring, and compressed sensing magnetic resonance imaging ({MRI}). Moreover, we conduct experiments that explain how the framework is best used and why it outperforms previous methods.},
	journaltitle = {{arXiv}:1705.08041 [cs]},
	author = {Diamond, Steven and Sitzmann, Vincent and Heide, Felix and Wetzstein, Gordon},
	urldate = {2019-07-19},
	date = {2017-05-22},
	eprinttype = {arxiv},
	eprint = {1705.08041},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, read},
	file = {Diamond et al_2017_Unrolled Optimization with Deep Priors.pdf:/Users/wpq/Dropbox (MIT)/zotero/Diamond et al_2017_Unrolled Optimization with Deep Priors.pdf:application/pdf}
}

@article{romanoLittleEngineThat2016,
	title = {The Little Engine that Could: Regularization by Denoising ({RED})},
	url = {http://arxiv.org/abs/1611.02862},
	shorttitle = {The Little Engine that Could},
	abstract = {Removal of noise from an image is an extensively studied problem in image processing. Indeed, the recent advent of sophisticated and highly effective denoising algorithms lead some to believe that existing methods are touching the ceiling in terms of noise removal performance. Can we leverage this impressive achievement to treat other tasks in image processing? Recent work has answered this question positively, in the form of the Plug-and-Play Prior (\$P{\textasciicircum}3\$) method, showing that any inverse problem can be handled by sequentially applying image denoising steps. This relies heavily on the {ADMM} optimization technique in order to obtain this chained denoising interpretation. Is this the only way in which tasks in image processing can exploit the image denoising engine? In this paper we provide an alternative, more powerful and more flexible framework for achieving the same goal. As opposed to the \$P{\textasciicircum}3\$ method, we offer Regularization by Denoising ({RED}): using the denoising engine in defining the regularization of the inverse problem. We propose an explicit image-adaptive Laplacian-based regularization functional, making the overall objective functional clearer and better defined. With a complete flexibility to choose the iterative optimization procedure for minimizing the above functional, {RED} is capable of incorporating any image denoising algorithm, treat general inverse problems very effectively, and is guaranteed to converge to the globally optimal result. We test this approach and demonstrate state-of-the-art results in the image deblurring and super-resolution problems.},
	journaltitle = {{arXiv}:1611.02862 [cs]},
	author = {Romano, Yaniv and Elad, Michael and Milanfar, Peyman},
	urldate = {2019-07-19},
	date = {2016-11-09},
	eprinttype = {arxiv},
	eprint = {1611.02862},
	keywords = {good, Computer Science - Computer Vision and Pattern Recognition, Mathematics - Numerical Analysis, read},
	file = {Romano et al_2016_The Little Engine that Could - Regularization by Denoising (RED).pdf:/Users/wpq/Dropbox (MIT)/zotero/Romano et al_2016_The Little Engine that Could - Regularization by Denoising (RED).pdf:application/pdf}
}

@article{meinhardtLearningProximalOperators2017,
	title = {Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems},
	url = {http://arxiv.org/abs/1704.03488},
	shorttitle = {Learning Proximal Operators},
	abstract = {While variational methods have been among the most powerful tools for solving linear inverse problems in imaging, deep (convolutional) neural networks have recently taken the lead in many challenging benchmarks. A remaining drawback of deep learning approaches is their requirement for an expensive retraining whenever the specific problem, the noise level, noise type, or desired measure of fidelity changes. On the contrary, variational methods have a plug-and-play nature as they usually consist of separate data fidelity and regularization terms. In this paper we study the possibility of replacing the proximal operator of the regularization used in many convex energy minimization algorithms by a denoising neural network. The latter therefore serves as an implicit natural image prior, while the data term can still be chosen independently. Using a fixed denoising neural network in exemplary problems of image deconvolution with different blur kernels and image demosaicking, we obtain state-of-the-art reconstruction results. These indicate the high generalizability of our approach and a reduction of the need for problem-specific training. Additionally, we discuss novel results on the analysis of possible optimization algorithms to incorporate the network into, as well as the choices of algorithm parameters and their relation to the noise level the neural network is trained on.},
	journaltitle = {{arXiv}:1704.03488 [cs]},
	author = {Meinhardt, Tim and Moeller, Michael and Hazirbas, Caner and Cremers, Daniel},
	urldate = {2019-07-19},
	date = {2017-04-11},
	eprinttype = {arxiv},
	eprint = {1704.03488},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, read},
	file = {Meinhardt et al_2017_Learning Proximal Operators - Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf:/Users/wpq/Dropbox (MIT)/zotero/Meinhardt et al_2017_Learning Proximal Operators - Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf:application/pdf}
}

@article{zhangLearningDeepCNN2017,
	title = {Learning Deep {CNN} Denoiser Prior for Image Restoration},
	url = {http://arxiv.org/abs/1704.03264},
	abstract = {Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective {CNN} (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.},
	journaltitle = {{arXiv}:1704.03264 [cs]},
	author = {Zhang, Kai and Zuo, Wangmeng and Gu, Shuhang and Zhang, Lei},
	urldate = {2019-07-19},
	date = {2017-04-11},
	eprinttype = {arxiv},
	eprint = {1704.03264},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, read},
	file = {Zhang et al_2017_Learning Deep CNN Denoiser Prior for Image Restoration.pdf:/Users/wpq/Dropbox (MIT)/zotero/Zhang et al_2017_Learning Deep CNN Denoiser Prior for Image Restoration.pdf:application/pdf}
}

@article{heideProxImaLEfficientImage2016,
	title = {{ProxImaL}: efficient image optimization using proximal algorithms},
	volume = {35},
	issn = {07300301},
	url = {http://dl.acm.org/citation.cfm?doid=2897824.2925875},
	doi = {10.1145/2897824.2925875},
	shorttitle = {{ProxImaL}},
	abstract = {Computational photography systems are becoming increasingly diverse, while computational resources—for example on mobile platforms—are rapidly increasing. As diverse as these camera systems may be, slightly different variants of the underlying image processing tasks, such as demosaicking, deconvolution, denoising, inpainting, image fusion, and alignment, are shared between all of these systems. Formal optimization methods have recently been demonstrated to achieve state-of-the-art quality for many of these applications. Unfortunately, different combinations of natural image priors and optimization algorithms may be optimal for different problems, and implementing and testing each combination is currently a time-consuming and error-prone process. {ProxImaL} is a domainspeciﬁc language and compiler for image optimization problems that makes it easy to experiment with different problem formulations and algorithm choices. The language uses proximal operators as the fundamental building blocks of a variety of linear and nonlinear image formation models and cost functions, advanced image priors, and noise models. The compiler intelligently chooses the best way to translate a problem formulation and choice of optimization algorithm into an efﬁcient solver implementation. In applications to the image processing pipeline, deconvolution in the presence of Poisson-distributed shot noise, and burst denoising, we show that a few lines of {ProxImaL} code can generate highly efﬁcient solvers that achieve state-of-the-art results. We also show applications to the nonlinear and nonconvex problem of phase retrieval.},
	pages = {1--15},
	number = {4},
	journaltitle = {{ACM} Transactions on Graphics},
	shortjournal = {{ACM} Trans. Graph.},
	author = {Heide, Felix and Diamond, Steven and Nießner, Matthias and Ragan-Kelley, Jonathan and Heidrich, Wolfgang and Wetzstein, Gordon},
	urldate = {2019-07-19},
	date = {2016-07-11},
	langid = {english},
	keywords = {tbr},
	file = {Heide et al_2016_ProxImaL - efficient image optimization using proximal algorithms.pdf:/Users/wpq/Dropbox (MIT)/zotero/Heide et al_2016_ProxImaL - efficient image optimization using proximal algorithms.pdf:application/pdf}
}

@article{chanPlugandPlayADMMImage2016,
	title = {Plug-and-Play {ADMM} for Image Restoration: Fixed Point Convergence and Applications},
	url = {http://arxiv.org/abs/1605.01710},
	shorttitle = {Plug-and-Play {ADMM} for Image Restoration},
	abstract = {Alternating direction method of multiplier ({ADMM}) is a widely used algorithm for solving constrained optimization problems in image restoration. Among many useful features, one critical feature of the {ADMM} algorithm is its modular structure which allows one to plug in any off-the-shelf image denoising algorithm for a subproblem in the {ADMM} algorithm. Because of the plug-in nature, this type of {ADMM} algorithms is coined the name "Plug-and-Play {ADMM}". Plug-and-Play {ADMM} has demonstrated promising empirical results in a number of recent papers. However, it is unclear under what conditions and by using what denoising algorithms would it guarantee convergence. Also, since Plug-and-Play {ADMM} uses a specific way to split the variables, it is unclear if fast implementation can be made for common Gaussian and Poissonian image restoration problems. In this paper, we propose a Plug-and-Play {ADMM} algorithm with provable fixed point convergence. We show that for any denoising algorithm satisfying an asymptotic criteria, called bounded denoisers, Plug-and-Play {ADMM} converges to a fixed point under a continuation scheme. We also present fast implementations for two image restoration problems on super-resolution and single-photon imaging. We compare Plug-and-Play {ADMM} with state-of-the-art algorithms in each problem type, and demonstrate promising experimental results of the algorithm.},
	journaltitle = {{arXiv}:1605.01710 [cs]},
	author = {Chan, Stanley H. and Wang, Xiran and Elgendy, Omar A.},
	urldate = {2019-07-19},
	date = {2016-05-05},
	eprinttype = {arxiv},
	eprint = {1605.01710},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, read},
	file = {Chan et al_2016_Plug-and-Play ADMM for Image Restoration - Fixed Point Convergence and Applications.pdf:/Users/wpq/Dropbox (MIT)/zotero/Chan et al_2016_Plug-and-Play ADMM for Image Restoration - Fixed Point Convergence and Applications.pdf:application/pdf}
}

@incollection{yangDeepADMMNetCompressive2016,
	title = {Deep {ADMM}-Net for Compressive Sensing {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	pages = {10--18},
	booktitle = {Advances in Neural Information Processing Systems 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	urldate = {2019-07-19},
	date = {2016},
	keywords = {tbr},
	file = {yang et al_2016_Deep ADMM-Net for Compressive Sensing MRI.pdf:/Users/wpq/Dropbox (MIT)/zotero/yang et al_2016_Deep ADMM-Net for Compressive Sensing MRI.pdf:application/pdf}
}

@article{chanAlgorithmInducedPriorImage2016,
	title = {Algorithm-Induced Prior for Image Restoration},
	volume = {abs/1602.00715},
	abstract = {This paper studies a type of image priors that are constructed implicitly through the alternating direction method of multiplier ({ADMM}) algorithm, called the algorithm-induced prior. Different from classical image priors which are defined before running the reconstruction algorithm, algorithm-induced priors are defined by the denoising procedure used to replace one of the two modules in the {ADMM} algorithm. Since such prior is not explicitly defined, analyzing the performance has been difficult in the past. 
Focusing on the class of symmetric smoothing filters, this paper presents an explicit expression of the prior induced by the {ADMM} algorithm. The new prior is reminiscent to the conventional graph Laplacian but with stronger reconstruction performance. It can also be shown that the overall reconstruction has an efficient closed-form implementation if the associated symmetric smoothing filter is low rank. The results are validated with experiments on image inpainting.},
	journaltitle = {{ArXiv}},
	author = {Chan, Stanley H.},
	date = {2016},
	eprinttype = {arxiv},
	eprint = {1602.00715},
	keywords = {Algorithm, Experiment, Image restoration, Inpainting, Laplacian matrix, Noise reduction, Optimization problem, Smoothing, tbr},
	file = {Chan_2016_Algorithm-Induced Prior for Image Restoration.pdf:/Users/wpq/Dropbox (MIT)/zotero/Chan_2016_Algorithm-Induced Prior for Image Restoration.pdf:application/pdf}
}

@inproceedings{venkatakrishnanPlugandPlayPriorsModel2013,
	title = {Plug-and-Play priors for model based reconstruction},
	doi = {10.1109/GlobalSIP.2013.6737048},
	abstract = {Model-based reconstruction is a powerful framework for solving a variety of inverse problems in imaging. In recent years, enormous progress has been made in the problem of denoising, a special case of an inverse problem where the forward model is an identity operator. Similarly, great progress has been made in improving model-based inversion when the forward model corresponds to complex physical measurements in applications such as X-ray {CT}, electron-microscopy, {MRI}, and ultrasound, to name just a few. However, combining state-of-the-art denoising algorithms (i.e., prior models) with state-of-the-art inversion methods (i.e., forward models) has been a challenge for many reasons. In this paper, we propose a flexible framework that allows state-of-the-art forward models of imaging systems to be matched with state-of-the-art priors or denoising models. This framework, which we term as Plug-and-Play priors, has the advantage that it dramatically simplifies software integration, and moreover, it allows state-of-the-art denoising methods that have no known formulation as an optimization problem to be used. We demonstrate with some simple examples how Plug-and-Play priors can be used to mix and match a wide variety of existing denoising models with a tomographic forward model, thus greatly expanding the range of possible problem solutions.},
	eventtitle = {2013 {IEEE} Global Conference on Signal and Information Processing},
	pages = {945--948},
	booktitle = {2013 {IEEE} Global Conference on Signal and Information Processing},
	author = {Venkatakrishnan, S. V. and Bouman, C. A. and Wohlberg, B.},
	date = {2013-12},
	keywords = {Computational modeling, denoising models, image denoising, image reconstruction, Image reconstruction, imaging system forward models, inverse problems, Inverse problems, model based reconstruction, Noise reduction, optimisation, Optimization, optimization problem, Phantoms, plug-and-play priors, read, software integration, tomographic forward model, Tomography},
	file = {Venkatakrishnan et al_2013_Plug-and-Play priors for model based reconstruction.pdf:/Users/wpq/Dropbox (MIT)/zotero/Venkatakrishnan et al_2013_Plug-and-Play priors for model based reconstruction.pdf:application/pdf}
}

@article{figueiredoRestorationPoissonianImages2010,
	title = {Restoration of Poissonian Images Using Alternating Direction Optimization},
	volume = {19},
	issn = {1057-7149, 1941-0042},
	url = {http://arxiv.org/abs/1001.2244},
	doi = {10.1109/TIP.2010.2053941},
	abstract = {Much research has been devoted to the problem of restoring Poissonian images, namely for medical and astronomical applications. However, the restoration of these images using state-of-the-art regularizers (such as those based on multiscale representations or total variation) is still an active research area, since the associated optimization problems are quite challenging. In this paper, we propose an approach to deconvolving Poissonian images, which is based on an alternating direction optimization method. The standard regularization (or maximum a posteriori) restoration criterion, which combines the Poisson log-likelihood with a (non-smooth) convex regularizer (log-prior), leads to hard optimization problems: the log-likelihood is non-quadratic and non-separable, the regularizer is non-smooth, and there is a non-negativity constraint. Using standard convex analysis tools, we present sufficient conditions for existence and uniqueness of solutions of these optimization problems, for several types of regularizers: total-variation, frame-based analysis, and frame-based synthesis. We attack these problems with an instance of the alternating direction method of multipliers ({ADMM}), which belongs to the family of augmented Lagrangian algorithms. We study sufficient conditions for convergence and show that these are satisfied, either under total-variation or frame-based (analysis and synthesis) regularization. The resulting algorithms are shown to outperform alternative state-of-the-art methods, both in terms of speed and restoration accuracy.},
	pages = {3133--3145},
	number = {12},
	journaltitle = {{IEEE} Transactions on Image Processing},
	shortjournal = {{IEEE} Trans. on Image Process.},
	author = {Figueiredo, Mário A. T. and Bioucas-Dias, José M.},
	urldate = {2019-07-19},
	date = {2010-12},
	eprinttype = {arxiv},
	eprint = {1001.2244},
	keywords = {94A08, 47N10, admm, denoising, Mathematics - Numerical Analysis, Mathematics - Optimization and Control, read},
	file = {Figueiredo_Bioucas-Dias_2010_Restoration of Poissonian Images Using Alternating Direction Optimization.pdf:/Users/wpq/Dropbox (MIT)/zotero/Figueiredo_Bioucas-Dias_2010_Restoration of Poissonian Images Using Alternating Direction Optimization.pdf:application/pdf}
}

@article{afonsoFastImageRecovery2010,
	title = {Fast Image Recovery Using Variable Splitting and Constrained Optimization},
	volume = {19},
	issn = {1057-7149},
	doi = {10.1109/TIP.2010.2047910},
	abstract = {We propose a new fast algorithm for solving one of the standard formulations of image restoration and reconstruction which consists of an unconstrained optimization problem where the objective includes anl2data-fidelity term and a nonsmooth regularizer. This formulation allows both wavelet-based (with orthogonal or frame-based representations) regularization or total-variation regularization. Our approach is based on a variable splitting to obtain an equivalent constrained optimization formulation, which is then addressed with an augmented Lagrangian method. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence has been proved. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is faster than the current state of the art methods.},
	pages = {2345--2356},
	number = {9},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Afonso, M. V. and Bioucas-Dias, J. M. and Figueiredo, M. A. T.},
	date = {2010-09},
	keywords = {alternating direction multiplier method, Augmented Lagrangian, augmented Lagrangian method, compressive sensing, Constraint optimization, convergence, Convergence, convex optimization, Convolution, equivalent constrained optimization formulation, fast image recovery, Fourier transforms, Image coding, image reconstruction, Image reconstruction, image restoration, Image restoration, inverse problems, Inverse problems, l2data-fidelity term, Lagrangian functions, nonsmooth regularizer, optimisation, Pixel, read, total variation, total-variation regularization, unconstrained optimization problem, variable splitting, wavelet transforms, wavelet-based regularization, wavelets},
	file = {Afonso et al_2010_Fast Image Recovery Using Variable Splitting and Constrained Optimization.pdf:/Users/wpq/Dropbox (MIT)/zotero/Afonso et al_2010_Fast Image Recovery Using Variable Splitting and Constrained Optimization.pdf:application/pdf}
}

@article{heideFlexISPFlexibleCamera2014,
	title = {{FlexISP}: A Flexible Camera Image Processing Framework},
	volume = {33},
	issn = {0730-0301},
	url = {http://doi.acm.org/10.1145/2661229.2661260},
	doi = {10.1145/2661229.2661260},
	shorttitle = {{FlexISP}},
	abstract = {Conventional pipelines for capturing, displaying, and storing images are usually defined as a series of cascaded modules, each responsible for addressing a particular problem. While this divide-and-conquer approach offers many benefits, it also introduces a cumulative error, as each step in the pipeline only considers the output of the previous step, not the original sensor data. We propose an end-to-end system that is aware of the camera and image model, enforces natural-image priors, while jointly accounting for common image processing steps like demosaicking, denoising, deconvolution, and so forth, all directly in a given output representation (e.g., {YUV}, {DCT}). Our system is flexible and we demonstrate it on regular Bayer images as well as images from custom sensors. In all cases, we achieve large improvements in image quality and signal reconstruction compared to state-of-the-art techniques. Finally, we show that our approach is capable of very efficiently handling high-resolution images, making even mobile implementations feasible.},
	pages = {231:1--231:13},
	number = {6},
	journaltitle = {{ACM} Trans. Graph.},
	author = {Heide, Felix and Steinberger, Markus and Tsai, Yun-Ta and Rouf, Mushfiqur and Pająk, Dawid and Reddy, Dikpal and Gallo, Orazio and Liu, Jing and Heidrich, Wolfgang and Egiazarian, Karen and Kautz, Jan and Pulli, Kari},
	urldate = {2019-07-19},
	date = {2014-11},
	keywords = {image processing, image reconstruction, read},
	file = {Heide et al_2014_FlexISP - A Flexible Camera Image Processing Framework.pdf:/Users/wpq/Dropbox (MIT)/zotero/Heide et al_2014_FlexISP - A Flexible Camera Image Processing Framework.pdf:application/pdf}
}

@inproceedings{changOneNetworkSolve2017,
	location = {Venice},
	title = {One Network to Solve Them All — Solving Linear Inverse Problems Using Deep Projection Models},
	isbn = {978-1-5386-1032-9},
	url = {https://ieeexplore.ieee.org/document/8237889/},
	doi = {10.1109/ICCV.2017.627},
	abstract = {While deep learning methods have achieved state-of-theart performance in many challenging inverse problems like image inpainting and super-resolution, they invariably involve problem-speciﬁc training of the networks. Under this approach, each inverse problem requires its own dedicated network. In scenarios where we need to solve a wide variety of problems, e.g., on a mobile camera, it is inefﬁcient and expensive to use these problem-speciﬁc networks. On the other hand, traditional methods using analytic signal priors can be used to solve any linear inverse problem; this often comes with a performance that is worse than learning-based methods. In this work, we provide a middle ground between the two kinds of methods — we propose a general framework to train a single deep neural network that solves arbitrary linear inverse problems. We achieve this by training a network that acts as a quasi-projection operator for the set of natural images and show that any linear inverse problem involving natural images can be solved using iterative methods. We empirically show that the proposed framework demonstrates superior performance over traditional methods using wavelet sparsity prior while achieving performance comparable to specially-trained networks on tasks including compressive sensing and pixel-wise inpainting.},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {5889--5898},
	booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Chang, J. H. Rick and Li, Chun-Liang and Poczos, Barnabas and Kumar, B. V. K. Vijaya and Sankaranarayanan, Aswin C.},
	urldate = {2019-07-19},
	date = {2017-10},
	langid = {english},
	keywords = {read},
	file = {Chang et al_2017_One Network to Solve Them All — Solving Linear Inverse Problems Using Deep Projection Models.pdf:/Users/wpq/Dropbox (MIT)/zotero/Chang et al_2017_One Network to Solve Them All — Solving Linear Inverse Problems Using Deep Projection Models.pdf:application/pdf}
}

@article{reehorstRegularizationDenoisingClarifications2018,
	title = {Regularization by Denoising: Clarifications and New Interpretations},
	url = {http://arxiv.org/abs/1806.02296},
	shorttitle = {Regularization by Denoising},
	abstract = {Regularization by Denoising ({RED}), as recently proposed by Romano, Elad, and Milanfar, is powerful image-recovery framework that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function. Experimental evidence suggests that the {RED} algorithms are state-of-the-art. We claim, however, that explicit regularization does not explain the {RED} algorithms. In particular, we show that many of the expressions in the paper by Romano et al. hold only when the denoiser has a symmetric Jacobian, and we demonstrate that such symmetry does not occur with practical denoisers such as non-local means, {BM}3D, {TNRD}, and {DnCNN}. To explain the {RED} algorithms, we propose a new framework called Score-Matching by Denoising ({SMD}), which aims to match a "score" (i.e., the gradient of a log-prior). We then show tight connections between {SMD}, kernel density estimation, and constrained minimum mean-squared error denoising. Furthermore, we interpret the {RED} algorithms from Romano et al. and propose new algorithms with acceleration and convergence guarantees. Finally, we show that the {RED} algorithms seek a consensus equilibrium solution, which facilitates a comparison to plug-and-play {ADMM}.},
	journaltitle = {{arXiv}:1806.02296 [cs]},
	author = {Reehorst, Edward T. and Schniter, Philip},
	urldate = {2019-07-19},
	date = {2018-06-06},
	eprinttype = {arxiv},
	eprint = {1806.02296},
	keywords = {tbr},
	file = {Reehorst_Schniter_2018_Regularization by Denoising - Clarifications and New Interpretations.pdf:/Users/wpq/Dropbox (MIT)/zotero/Reehorst_Schniter_2018_Regularization by Denoising - Clarifications and New Interpretations.pdf:application/pdf}
}

@article{mataevDeepREDDeepImage2019,
	title = {{DeepRED}: Deep Image Prior Powered by {RED}},
	url = {http://arxiv.org/abs/1903.10176},
	shorttitle = {{DeepRED}},
	abstract = {Inverse problems in imaging are extensively studied, with a variety of strategies, tools, and theory that have been accumulated over the years. Recently, this field has been immensely influenced by the emergence of deep-learning techniques. One such contribution, which is the focus of this paper, is the Deep Image Prior ({DIP}) work by Ulyanov, Vedaldi, and Lempitsky (2018). {DIP} offers a new approach towards the regularization of inverse problems, obtained by forcing the recovered image to be synthesized from a given deep architecture. While {DIP} has been shown to be effective, its results fall short when compared to state-of-the-art alternatives. In this work, we aim to boost {DIP} by adding an explicit prior, which enriches the overall regularization effect in order to lead to better-recovered images. More specifically, we propose to bring-in the concept of Regularization by Denoising ({RED}), which leverages existing denoisers for regularizing inverse problems. Our work shows how the two ({DeepRED}) can be merged to a highly effective recovery process while avoiding the need to differentiate the chosen denoiser, and leading to very effective results, demonstrated for several tested inverse problems.},
	journaltitle = {{arXiv}:1903.10176 [cs, eess]},
	author = {Mataev, Gary and Elad, Michael and Milanfar, Peyman},
	urldate = {2019-07-19},
	date = {2019-03-25},
	eprinttype = {arxiv},
	eprint = {1903.10176},
	keywords = {read},
	file = {Mataev et al_2019_DeepRED - Deep Image Prior Powered by RED.pdf:/Users/wpq/Dropbox (MIT)/zotero/Mataev et al_2019_DeepRED - Deep Image Prior Powered by RED.pdf:application/pdf}
}

@article{gemanConstrainedRestorationRecovery1992,
	title = {Constrained restoration and the recovery of discontinuities},
	volume = {14},
	issn = {0162-8828},
	doi = {10.1109/34.120331},
	abstract = {The linear image restoration problem is to recover an original brightness distribution X/sup 0/ given the blurred and noisy observations Y={KX}/sup 0/+B, where K and B represent the point spread function and measurement error, respectively. This problem is typical of ill-conditioned inverse problems that frequently arise in low-level computer vision. A conventional method to stabilize the problem is to introduce a priori constraints on X/sup 0/ and design a cost functional H(X) over images X, which is a weighted average of the prior constraints (regularization term) and posterior constraints (data term); the reconstruction is then the image X, which minimizes H. A prominent weakness in this approach, especially with quadratic-type stabilizers, is the difficulty in recovering discontinuities. The authors therefore examine prior smoothness constraints of a different form, which permit the recovery of discontinuities without introducing auxiliary variables for marking the location of jumps and suspending the constraints in their vicinity. In this sense, discontinuities are addressed implicitly rather than explicitly.{\textless}{\textgreater}},
	pages = {367--383},
	number = {3},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, D. and Reynolds, G.},
	date = {1992-03},
	keywords = {half quadratic splitting, tbr},
	file = {Geman_Reynolds_1992_Constrained restoration and the recovery of discontinuities.pdf:/Users/wpq/Dropbox (MIT)/zotero/Geman_Reynolds_1992_Constrained restoration and the recovery of discontinuities.pdf:application/pdf}
}

@article{gemanNonlinearImageRecovery1995,
	title = {Nonlinear image recovery with half-quadratic regularization},
	volume = {4},
	issn = {1057-7149},
	doi = {10.1109/83.392335},
	abstract = {One popular method for the recovery of an ideal intensity image from corrupted or indirect measurements is regularization: minimize an objective function that enforces a roughness penalty in addition to coherence with the data. Linear estimates are relatively easy to compute but generally introduce systematic errors; for example, they are incapable of recovering discontinuities and other important image attributes. In contrast, nonlinear estimates are more accurate but are often far less accessible. This is particularly true when the objective function is nonconvex, and the distribution of each data component depends on many image components through a linear operator with broad support. Our approach is based on an auxiliary array and an extended objective function in which the original variables appear quadratically and the auxiliary variables are decoupled. Minimizing over the auxiliary array alone yields the original function so that the original image estimate can be obtained by joint minimization. This can be done efficiently by Monte Carlo methods, for example by {FFT}-based annealing using a Markov chain that alternates between (global) transitions from one array to the other. Experiments are reported in optical astronomy, with space telescope data, and computed tomography.{\textless}{\textgreater}},
	pages = {932--946},
	number = {7},
	journaltitle = {{IEEE} Transactions on Image Processing},
	author = {Geman, D. and {Chengda Yang}},
	date = {1995-07},
	keywords = {tbr},
	file = {Geman_Chengda Yang_1995_Nonlinear image recovery with half-quadratic regularization.pdf:/Users/wpq/Dropbox (MIT)/zotero/Geman_Chengda Yang_1995_Nonlinear image recovery with half-quadratic regularization.pdf:application/pdf}
}

@article{ulyanovDeepImagePrior2017,
	title = {Deep Image Prior},
	url = {http://arxiv.org/abs/1711.10925},
	abstract = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity. Code and supplementary material are available at https://dmitryulyanov.github.io/deep\_image\_prior .},
	journaltitle = {{arXiv}:1711.10925 [cs, stat]},
	author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	urldate = {2019-07-21},
	date = {2017-11-29},
	eprinttype = {arxiv},
	eprint = {1711.10925},
	keywords = {read},
	file = {Ulyanov et al_2017_Deep Image Prior.pdf:/Users/wpq/Dropbox (MIT)/zotero/Ulyanov et al_2017_Deep Image Prior.pdf:application/pdf}
}

@inproceedings{ryuPlugandPlayMethodsProvably2019,
	title = {Plug-and-Play Methods Provably Converge with Properly Trained Denoisers},
	url = {http://proceedings.mlr.press/v97/ryu19a.html},
	abstract = {Plug-and-play ({PnP}) is a non-convex framework that integrates modern denoising priors, such as {BM}3D or deep learning-based denoisers, into {ADMM} or other proximal algorithms. An advantage of {PnP} is ...},
	eventtitle = {International Conference on Machine Learning},
	pages = {5546--5557},
	booktitle = {International Conference on Machine Learning},
	author = {Ryu, Ernest and Liu, Jialin and Wang, Sicheng and Chen, Xiaohan and Wang, Zhangyang and Yin, Wotao},
	urldate = {2019-07-19},
	date = {2019-05-24},
	langid = {english},
	keywords = {read},
	file = {Ryu et al_2019_Plug-and-Play Methods Provably Converge with Properly Trained Denoisers.pdf:/Users/wpq/Dropbox (MIT)/zotero/Ryu et al_2019_Plug-and-Play Methods Provably Converge with Properly Trained Denoisers.pdf:application/pdf}
}

@inproceedings{rothFieldsExpertsFramework2005,
	location = {San Diego, {CA}, {USA}},
	title = {Fields of Experts: A Framework for Learning Image Priors},
	volume = {2},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467533/},
	doi = {10.1109/CVPR.2005.160},
	shorttitle = {Fields of Experts},
	abstract = {We develop a framework for learning generic, expressive image priors that capture the statistics of natural scenes and can be used for a variety of machine vision tasks. The approach extends traditional Markov Random Field ({MRF}) models by learning potential functions over extended pixel neighborhoods. Field potentials are modeled using a Products-of-Experts framework that exploits nonlinear functions of many linear ﬁlter responses. In contrast to previous {MRF} approaches all parameters, including the linear ﬁlters themselves, are learned from training data. We demonstrate the capabilities of this Field of Experts model with two example applications, image denoising and image inpainting, which are implemented using a simple, approximate inference scheme. While the model is trained on a generic image database and is not tuned toward a speciﬁc application, we obtain results that compete with and even outperform specialized techniques.},
	eventtitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	pages = {860--867},
	booktitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	publisher = {{IEEE}},
	author = {Roth, S. and Black, M.J.},
	urldate = {2019-07-19},
	date = {2005},
	langid = {english},
	keywords = {tbr},
	file = {Roth_Black_2005_Fields of Experts - A Framework for Learning Image Priors.pdf:/Users/wpq/Dropbox (MIT)/zotero/Roth_Black_2005_Fields of Experts - A Framework for Learning Image Priors.pdf:application/pdf}
}

@article{liuInfusingLearnedPriors2019,
	title = {Infusing Learned Priors into Model-Based Multispectral Imaging},
	url = {http://arxiv.org/abs/1909.09313},
	abstract = {We introduce a new algorithm for regularized reconstruction of multispectral ({MS}) images from noisy linear measurements. Unlike traditional approaches, the proposed algorithm regularizes the recovery problem by using a prior specified {\textbackslash}emph\{only\} through a learned denoising function. More specifically, we propose a new accelerated gradient method ({AGM}) variant of regularization by denoising ({RED}) for model-based {MS} image reconstruction. The key ingredient of our approach is the three-dimensional (3D) deep neural net ({DNN}) denoiser that can fully leverage spationspectral correlations within {MS} images. Our results suggest the generalizability of our {MS}-{RED} algorithm, where a single trained {DNN} can be used to solve several different {MS} imaging problems.},
	journaltitle = {{arXiv}:1909.09313 [cs, eess]},
	author = {Liu, Jiaming and Sun, Yu and Kamilov, Ulugbek S.},
	urldate = {2020-05-09},
	date = {2019-09-20},
	eprinttype = {arxiv},
	eprint = {1909.09313},
	keywords = {tbr},
	file = {Liu et al_2019_Infusing Learned Priors into Model-Based Multispectral Imaging.pdf:/Users/wpq/Dropbox (MIT)/zotero/Liu et al_2019_Infusing Learned Priors into Model-Based Multispectral Imaging.pdf:application/pdf}
}

@article{yuanPlugandPlayAlgorithmsLargescale2020,
	title = {Plug-and-Play Algorithms for Large-scale Snapshot Compressive Imaging},
	url = {http://arxiv.org/abs/2003.13654},
	abstract = {Snapshot compressive imaging ({SCI}) aims to capture the high-dimensional (usually 3D) images using a 2D sensor (detector) in a single snapshot. Though enjoying the advantages of low-bandwidth, low-power and low-cost, applying {SCI} to large-scale problems ({HD} or {UHD} videos) in our daily life is still challenging. The bottleneck lies in the reconstruction algorithms; they are either too slow (iterative optimization algorithms) or not flexible to the encoding process (deep learning based end-to-end networks). In this paper, we develop fast and flexible algorithms for {SCI} based on the plug-and-play ({PnP}) framework. In addition to the widely used {PnP}-{ADMM} method, we further propose the {PnP}-{GAP} (generalized alternating projection) algorithm with a lower computational workload and prove the \{global convergence\} of {PnP}-{GAP} under the {SCI} hardware constraints. By employing deep denoising priors, we first time show that {PnP} can recover a {UHD} color video (\$3840{\textbackslash}times 1644{\textbackslash}times 48\$ with {PNSR} above 30dB) from a snapshot 2D measurement. Extensive results on both simulation and real datasets verify the superiority of our proposed algorithm. The code is available at https://github.com/liuyang12/{PnP}-{SCI}.},
	journaltitle = {{arXiv}:2003.13654 [cs, eess]},
	author = {Yuan, Xin and Liu, Yang and Suo, Jinli and Dai, Qionghai},
	urldate = {2020-05-28},
	date = {2020-03-30},
	eprinttype = {arxiv},
	eprint = {2003.13654},
	keywords = {tbr},
	file = {Yuan et al_2020_Plug-and-Play Algorithms for Large-scale Snapshot Compressive Imaging.pdf:/Users/wpq/Dropbox (MIT)/zotero/Yuan et al_2020_Plug-and-Play Algorithms for Large-scale Snapshot Compressive Imaging.pdf:application/pdf}
}

@incollection{sunBlockCoordinateRegularization2019,
	title = {Block Coordinate Regularization by Denoising},
	url = {http://papers.nips.cc/paper/8330-block-coordinate-regularization-by-denoising.pdf},
	pages = {382--392},
	booktitle = {Advances in Neural Information Processing Systems 32},
	publisher = {Curran Associates, Inc.},
	author = {Sun, Yu and Liu, Jiaming and Kamilov, Ulugbek},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d\{{\textbackslash}textbackslash\}textquotesingle and Fox, E. and Garnett, R.},
	urldate = {2020-05-28},
	date = {2019},
	keywords = {read},
	file = {Sun et al_2019_Block Coordinate Regularization by Denoising.pdf:/Users/wpq/Dropbox (MIT)/zotero/Sun et al_2019_Block Coordinate Regularization by Denoising.pdf:application/pdf}
}

@article{kamilovPlugandPlayPriorsApproach2017,
	title = {A Plug-and-Play Priors Approach for Solving Nonlinear Imaging Inverse Problems},
	volume = {24},
	issn = {1558-2361},
	doi = {10.1109/LSP.2017.2763583},
	abstract = {In the past two decades, nonlinear image reconstruction methods have led to substantial improvements in the capabilities of numerous imaging systems. Such methods are traditionally formulated as optimization problems that are solved iteratively by simultaneously enforcing data consistency and incorporating prior models. Recently, the Plug-and-Play Priors ({PPP}) framework suggested that by using more sophisticated denoisers, not necessarily corresponding to an optimization objective, it is possible to improve the quality of reconstructed images. In this letter, we show that the {PPP} approach is applicable beyond linear inverse problems. In particular, we develop the fast iterative shrinkage/thresholding algorithm variant of {PPP} for model-based nonlinear inverse scattering. The key advantage of the proposed formulation over the original {ADMM}-based one is that it does not need to perform an inversion on the forward model. We show that the proposed method produces high quality images using both simulated and experimentally measured data.},
	pages = {1872--1876},
	number = {12},
	journaltitle = {{IEEE} Signal Processing Letters},
	author = {Kamilov, Ulugbek S. and Mansour, Hassan and Wohlberg, Brendt},
	date = {2017-12},
	note = {Conference Name: {IEEE} Signal Processing Letters},
	keywords = {tbr},
	file = {Kamilov et al_2017_A Plug-and-Play Priors Approach for Solving Nonlinear Imaging Inverse Problems.pdf:/Users/wpq/Dropbox (MIT)/zotero/Kamilov et al_2017_A Plug-and-Play Priors Approach for Solving Nonlinear Imaging Inverse Problems.pdf:application/pdf}
}

@article{bigdeliDeepMeanShiftPriors2017,
	title = {Deep Mean-Shift Priors for Image Restoration},
	url = {http://arxiv.org/abs/1709.03749},
	abstract = {In this paper we introduce a natural image prior that directly represents a Gaussian-smoothed version of the natural image distribution. We include our prior in a formulation of image restoration as a Bayes estimator that also allows us to solve noise-blind image restoration problems. We show that the gradient of our prior corresponds to the mean-shift vector on the natural image distribution. In addition, we learn the mean-shift vector field using denoising autoencoders, and use it in a gradient descent approach to perform Bayes risk minimization. We demonstrate competitive results for noise-blind deblurring, super-resolution, and demosaicing.},
	journaltitle = {{arXiv}:1709.03749 [cs]},
	author = {Bigdeli, Siavash Arjomand and Jin, Meiguang and Favaro, Paolo and Zwicker, Matthias},
	urldate = {2020-05-28},
	date = {2017-10-04},
	eprinttype = {arxiv},
	eprint = {1709.03749},
	keywords = {tbr},
	file = {Bigdeli et al_2017_Deep Mean-Shift Priors for Image Restoration.pdf:/Users/wpq/Dropbox (MIT)/zotero/Bigdeli et al_2017_Deep Mean-Shift Priors for Image Restoration.pdf:application/pdf}
}